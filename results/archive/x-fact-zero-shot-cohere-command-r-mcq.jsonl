{"dataset": "x-fact-zero-shot", "idx_after_dropna": 3, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:24:50.897118", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 0, "raw_pred": "F", "pred": "mostly false", "ground_truth": "true", "time": "2025-05-18 13:24:50.898871", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 4, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 13:24:50.921227", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "gu", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 1, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 13:24:50.924313", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 2, "raw_pred": "A", "pred": "true", "ground_truth": "partly true/misleading", "time": "2025-05-18 13:24:50.934367", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "mr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 6, "raw_pred": "G", "pred": "false", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 13:24:51.055371", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 7, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:24:51.076781", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 5, "raw_pred": "G", "pred": "false", "ground_truth": "mostly true", "time": "2025-05-18 13:24:51.080884", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 9, "raw_pred": "G", "pred": "false", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 13:24:51.097891", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 8, "raw_pred": "F", "pred": "mostly false", "ground_truth": "partly true/misleading", "time": "2025-05-18 13:24:51.107497", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 11, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 13:24:51.224320", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "nl", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 10, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:24:51.246830", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "si", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 12, "raw_pred": "D", "pred": "complicated/hard to categorise", "ground_truth": "mostly false", "time": "2025-05-18 13:24:51.254639", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "az", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 13, "raw_pred": "G", "pred": "false", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 13:24:51.266321", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 14, "raw_pred": "A", "pred": "true", "ground_truth": "false", "time": "2025-05-18 13:24:51.272185", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 15, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 13:24:51.402347", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 19, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:24:51.422494", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "az", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 16, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 13:24:51.440719", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 17, "raw_pred": "D", "pred": "complicated/hard to categorise", "ground_truth": "false", "time": "2025-05-18 13:24:51.449007", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 18, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 13:24:51.449532", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "mr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 20, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 13:24:51.566959", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 21, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 13:24:51.600935", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 22, "raw_pred": "A", "pred": "true", "ground_truth": "false", "time": "2025-05-18 13:24:51.606501", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "az", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 24, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 13:24:51.622379", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 23, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:24:51.628042", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 26, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:24:51.767664", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 27, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:24:51.771814", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 28, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 13:24:51.787268", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 29, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 13:24:51.815159", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 25, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 13:24:51.873881", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "pa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 31, "raw_pred": "F", "pred": "mostly false", "ground_truth": "partly true/misleading", "time": "2025-05-18 13:24:51.941695", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 30, "raw_pred": "G", "pred": "false", "ground_truth": "true", "time": "2025-05-18 13:24:51.959432", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 32, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:24:51.979404", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 33, "raw_pred": "A", "pred": "true", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 13:24:51.980240", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 34, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 13:24:52.031852", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 35, "raw_pred": "G", "pred": "false", "ground_truth": "mostly true", "time": "2025-05-18 13:24:52.099635", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 36, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:24:52.132467", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 38, "raw_pred": "F", "pred": "mostly false", "ground_truth": "partly true/misleading", "time": "2025-05-18 13:24:52.147556", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 37, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:24:52.163359", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 39, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "mostly false", "time": "2025-05-18 13:24:52.191603", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 40, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 13:24:52.270778", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "nl", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 41, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:24:52.287697", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 42, "raw_pred": "B", "pred": "mostly true", "ground_truth": "mostly true", "time": "2025-05-18 13:24:52.315783", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 43, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:24:52.332152", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 44, "raw_pred": "G", "pred": "false", "ground_truth": "true", "time": "2025-05-18 13:24:52.335927", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 45, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:24:52.443270", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 46, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 13:24:52.448732", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 47, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "partly true/misleading", "time": "2025-05-18 13:24:52.469293", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 49, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:24:52.484666", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 48, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:24:52.493291", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 50, "raw_pred": "G", "pred": "false", "ground_truth": "true", "time": "2025-05-18 13:24:52.608189", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 52, "raw_pred": "A", "pred": "true", "ground_truth": "false", "time": "2025-05-18 13:24:52.616838", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "az", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 51, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:24:52.618116", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "si", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 54, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:24:52.659732", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "az", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 53, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 13:24:52.667904", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 56, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 13:24:52.801796", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 58, "raw_pred": "A", "pred": "true", "ground_truth": "true", "time": "2025-05-18 13:24:52.804670", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 57, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 13:24:52.810518", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "si", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 55, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 13:24:52.812643", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 59, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 13:24:52.822094", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 63, "raw_pred": "G", "pred": "false", "ground_truth": "true", "time": "2025-05-18 13:24:53.065115", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 60, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 13:24:53.066221", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 62, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 13:24:53.077784", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 61, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:24:53.087793", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 64, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:24:53.097196", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 65, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 13:24:53.300441", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 66, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:24:53.307527", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 69, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 13:24:53.326770", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 67, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:24:53.331498", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "mr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 68, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 13:24:53.332346", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "pa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 70, "raw_pred": "F", "pred": "mostly false", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 13:24:53.476420", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 71, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:24:53.483165", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 74, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:24:53.500335", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 72, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:24:53.512224", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 73, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 13:24:53.517858", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 76, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:24:53.644013", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "si", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 75, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 13:24:53.655800", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "mr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 78, "raw_pred": "F", "pred": "mostly false", "ground_truth": "partly true/misleading", "time": "2025-05-18 13:24:53.669097", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 77, "raw_pred": "G", "pred": "false", "ground_truth": "true", "time": "2025-05-18 13:24:53.686997", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 79, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:24:53.699813", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 80, "raw_pred": "G", "pred": "false", "ground_truth": "true", "time": "2025-05-18 13:24:53.798454", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 81, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:24:53.814426", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 82, "raw_pred": "D", "pred": "complicated/hard to categorise", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 13:24:53.836795", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 83, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:24:53.847650", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 84, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:24:53.852171", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 85, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 13:24:53.942511", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 86, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "partly true/misleading", "time": "2025-05-18 13:24:53.962481", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 87, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 13:24:53.996506", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 88, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:24:53.997232", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 89, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 13:24:54.014347", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 90, "raw_pred": "G", "pred": "false", "ground_truth": "true", "time": "2025-05-18 13:24:54.083663", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 91, "raw_pred": "G", "pred": "false", "ground_truth": "true", "time": "2025-05-18 13:24:54.132724", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 93, "raw_pred": "G", "pred": "false", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 13:24:54.140562", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 92, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 13:24:54.156529", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 94, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 13:24:54.171524", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 95, "raw_pred": "G", "pred": "false", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 13:24:54.226680", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 96, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 13:24:54.300074", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 99, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:24:54.304845", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "nl", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 98, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 13:24:54.312976", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 97, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 13:24:54.318401", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 100, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:24:54.380876", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 101, "raw_pred": "G", "pred": "false", "ground_truth": "true", "time": "2025-05-18 13:24:54.482288", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 104, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:24:54.484261", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "nl", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 103, "raw_pred": "G", "pred": "false", "ground_truth": "true", "time": "2025-05-18 13:24:54.485020", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "az", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 102, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:24:54.498360", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 105, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:24:54.541282", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 108, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "true", "time": "2025-05-18 13:24:54.668468", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 106, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 13:24:54.682125", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 109, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 13:24:54.698750", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 107, "raw_pred": "G", "pred": "false", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 13:24:54.705135", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 110, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:24:54.713817", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "si", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 111, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 13:24:54.831118", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "mr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 112, "raw_pred": "G", "pred": "false", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 13:24:54.845718", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 113, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:24:54.854400", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 115, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 13:24:54.874464", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 114, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 13:24:54.881470", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 116, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:24:54.999239", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 119, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 13:24:55.023080", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 117, "raw_pred": "G", "pred": "false", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 13:24:55.026543", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 120, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 13:24:55.044433", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 118, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:24:55.045076", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "gu", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 121, "raw_pred": "A", "pred": "true", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 13:24:55.143941", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 122, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 13:24:55.180891", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 123, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 13:24:55.190393", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 125, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:24:55.213662", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 124, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 13:24:55.236559", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 126, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:24:55.307375", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "si", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 128, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 13:24:55.350543", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 129, "raw_pred": "F", "pred": "mostly false", "ground_truth": "mostly true", "time": "2025-05-18 13:24:55.353744", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 127, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 13:24:55.370844", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 130, "raw_pred": "D", "pred": "complicated/hard to categorise", "ground_truth": "true", "time": "2025-05-18 13:24:55.372675", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 131, "raw_pred": "F", "pred": "mostly false", "ground_truth": "partly true/misleading", "time": "2025-05-18 13:24:55.467212", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "nl", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 133, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 13:24:55.497233", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 135, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 13:24:55.520904", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "pa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 132, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:24:55.522840", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "nl", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 134, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:24:55.548660", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 137, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 13:24:55.642338", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "gu", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 136, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 13:24:55.644592", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 138, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:24:55.705257", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "pa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 140, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:24:55.708348", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 139, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 13:24:55.711512", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 142, "raw_pred": "D", "pred": "complicated/hard to categorise", "ground_truth": "mostly true", "time": "2025-05-18 13:24:55.789321", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 141, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 13:24:55.822187", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 144, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:24:55.866876", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 143, "raw_pred": "F", "pred": "mostly false", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 13:24:55.883481", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 145, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 13:24:55.886491", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 146, "raw_pred": "G", "pred": "false", "ground_truth": "true", "time": "2025-05-18 13:24:55.951490", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 147, "raw_pred": "G", "pred": "false", "ground_truth": "true", "time": "2025-05-18 13:24:55.970569", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 148, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 13:24:56.012492", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 150, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 13:24:56.040655", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 149, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 13:24:56.041364", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 152, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 13:24:56.109634", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 151, "raw_pred": "G", "pred": "false", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 13:24:56.123166", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "nl", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 154, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:24:56.201823", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "pa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 153, "raw_pred": "G", "pred": "false", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 13:24:56.198189", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 155, "raw_pred": "A", "pred": "true", "ground_truth": "false", "time": "2025-05-18 13:24:56.214086", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 156, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:24:56.278943", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 157, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:24:56.289295", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "pa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 158, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 13:24:56.374993", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 160, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "partly true/misleading", "time": "2025-05-18 13:24:56.385834", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 159, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 13:24:56.405075", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "pa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 161, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 13:24:56.449428", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"score": 0}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 164, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 13:24:56.523064", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "az", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 163, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:24:56.535422", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 165, "raw_pred": "G", "pred": "false", "ground_truth": "true", "time": "2025-05-18 13:24:56.569493", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 166, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:24:56.626496", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "pa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 167, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 13:24:56.641098", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 168, "raw_pred": "D", "pred": "complicated/hard to categorise", "ground_truth": "partly true/misleading", "time": "2025-05-18 13:24:56.698468", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 170, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 13:24:56.711260", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 169, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:24:56.714288", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 171, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 13:24:56.763228", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 172, "raw_pred": "F", "pred": "mostly false", "ground_truth": "partly true/misleading", "time": "2025-05-18 13:24:56.818513", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "mr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 173, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:24:56.858684", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 175, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 13:24:56.883208", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 174, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 13:24:56.894264", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "si", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 176, "raw_pred": "D", "pred": "complicated/hard to categorise", "ground_truth": "true", "time": "2025-05-18 13:24:56.918339", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "nl", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 177, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "partly true/misleading", "time": "2025-05-18 13:24:56.959376", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 178, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 13:24:57.034680", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 180, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:24:57.035662", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 179, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 13:24:57.062750", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "pa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 181, "raw_pred": "F", "pred": "mostly false", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 13:24:57.096840", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 182, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:24:57.130480", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 183, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 13:24:57.208755", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 184, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:24:57.215732", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 186, "raw_pred": "G", "pred": "false", "ground_truth": "other", "time": "2025-05-18 13:24:57.237384", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 185, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:24:57.244875", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 187, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 13:24:57.284719", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 188, "raw_pred": "B", "pred": "mostly true", "ground_truth": "false", "time": "2025-05-18 13:24:57.352148", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 189, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:24:57.380020", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 191, "raw_pred": "A", "pred": "true", "ground_truth": "false", "time": "2025-05-18 13:24:57.400981", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 190, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "partly true/misleading", "time": "2025-05-18 13:24:57.421952", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 192, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 13:24:57.425564", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 193, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:24:57.512039", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 194, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 13:24:57.555023", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 195, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "mostly true", "time": "2025-05-18 13:24:57.559909", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 197, "raw_pred": "G", "pred": "false", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 13:24:57.563930", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 196, "raw_pred": "G", "pred": "false", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 13:24:57.581006", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 198, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:24:57.648339", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 200, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 13:24:57.713453", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "gu", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 199, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 13:24:57.738360", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 201, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:24:57.745250", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 202, "raw_pred": "G", "pred": "false", "ground_truth": "true", "time": "2025-05-18 13:24:57.746287", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 203, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:24:57.809373", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 204, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:24:57.888613", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "mr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 206, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:24:57.894527", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "az", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 205, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:24:57.915701", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "mr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 207, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:24:57.919645", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 208, "raw_pred": "G", "pred": "false", "ground_truth": "true", "time": "2025-05-18 13:24:57.946611", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 209, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:24:58.038906", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 210, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 13:24:58.059491", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 212, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:24:58.075609", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 211, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "mostly false", "time": "2025-05-18 13:24:58.090707", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "az", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 213, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 13:24:58.123670", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 214, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "mostly false", "time": "2025-05-18 13:24:58.199058", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 215, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 13:24:58.224739", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 216, "raw_pred": "G", "pred": "false", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 13:24:58.235481", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 217, "raw_pred": "A", "pred": "true", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 13:24:58.262077", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 218, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:24:58.286802", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "pa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 219, "raw_pred": "F", "pred": "mostly false", "ground_truth": "mostly true", "time": "2025-05-18 13:24:58.362017", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 220, "raw_pred": "F", "pred": "mostly false", "ground_truth": "partly true/misleading", "time": "2025-05-18 13:24:58.370914", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 221, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 13:24:58.395094", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 223, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:24:58.427346", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 222, "raw_pred": "G", "pred": "false", "ground_truth": "true", "time": "2025-05-18 13:24:58.432602", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 224, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 13:24:58.532652", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "si", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 226, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 13:24:58.533444", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "nl", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 225, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 13:24:58.536170", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 227, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "partly true/misleading", "time": "2025-05-18 13:24:58.586131", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 228, "raw_pred": "F", "pred": "mostly false", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 13:24:58.597637", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 230, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 13:24:58.696390", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 229, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:24:58.723314", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "mr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 231, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:24:58.738699", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "az", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 232, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 13:24:58.754165", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 233, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:24:58.762025", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 234, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "partly true/misleading", "time": "2025-05-18 13:24:58.866953", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 235, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 13:24:58.884610", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 236, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:24:58.897374", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "si", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 237, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:24:58.910316", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 238, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 13:24:58.921559", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "nl", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 239, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:24:59.005856", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 240, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 13:24:59.056667", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "gu", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 241, "raw_pred": "G", "pred": "false", "ground_truth": "true", "time": "2025-05-18 13:24:59.080546", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 242, "raw_pred": "F", "pred": "mostly false", "ground_truth": "partly true/misleading", "time": "2025-05-18 13:24:59.090140", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 243, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 13:24:59.090479", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 244, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 13:24:59.180061", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 245, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 13:24:59.197017", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 246, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:24:59.221695", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 248, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:24:59.249757", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "si", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 247, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 13:24:59.261636", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 249, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 13:24:59.345968", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 250, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:24:59.356464", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 251, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 13:24:59.383721", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 252, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 13:24:59.393774", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 253, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 13:24:59.421559", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 254, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 13:24:59.526405", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "gu", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 255, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 13:24:59.533222", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "gu", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 256, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 13:24:59.543124", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 257, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:24:59.566035", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 258, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 13:24:59.581699", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 259, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 13:24:59.686430", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "pa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 260, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:24:59.704349", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 261, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 13:24:59.730294", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 262, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 13:24:59.744057", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 263, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:24:59.750168", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "gu", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 265, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:24:59.843568", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 264, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 13:24:59.864228", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 268, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:24:59.888275", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 266, "raw_pred": "A", "pred": "true", "ground_truth": "false", "time": "2025-05-18 13:24:59.898267", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 267, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 13:24:59.907458", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "mr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 269, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:25:00.002690", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 270, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:25:00.040336", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 272, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:25:00.066100", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 273, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 13:25:00.067266", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 271, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 13:25:00.074922", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 274, "raw_pred": "D", "pred": "complicated/hard to categorise", "ground_truth": "partly true/misleading", "time": "2025-05-18 13:25:00.166822", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "nl", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 275, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 13:25:00.204926", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "az", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 277, "raw_pred": "G", "pred": "false", "ground_truth": "other", "time": "2025-05-18 13:25:00.222152", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 276, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:25:00.238979", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "az", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 278, "raw_pred": "G", "pred": "false", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 13:25:00.246653", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 279, "raw_pred": "D", "pred": "complicated/hard to categorise", "ground_truth": "mostly false", "time": "2025-05-18 13:25:00.338289", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "az", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 280, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 13:25:00.346758", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 281, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:25:00.395945", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 283, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:25:00.415113", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 282, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:25:00.420760", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 285, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 13:25:00.512545", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 284, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 13:25:00.513008", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 287, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 13:25:00.565060", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 286, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:25:00.573056", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 288, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 13:25:00.582663", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 289, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:25:00.677383", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 290, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "mostly true", "time": "2025-05-18 13:25:00.685222", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 293, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 13:25:00.760469", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 291, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:25:00.763337", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 292, "raw_pred": "G", "pred": "false", "ground_truth": "mostly true", "time": "2025-05-18 13:25:00.766262", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 294, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:25:00.823022", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 295, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:25:00.856397", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 297, "raw_pred": "F", "pred": "mostly false", "ground_truth": "partly true/misleading", "time": "2025-05-18 13:25:00.940970", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 296, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 13:25:00.962641", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 298, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 13:25:00.969463", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 299, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 13:25:00.990579", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 300, "raw_pred": "F", "pred": "mostly false", "ground_truth": "mostly true", "time": "2025-05-18 13:25:01.013418", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 302, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 13:25:01.108840", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 301, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "mostly false", "time": "2025-05-18 13:25:01.112760", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "az", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 303, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "partly true/misleading", "time": "2025-05-18 13:25:01.132883", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 305, "raw_pred": "A", "pred": "true", "ground_truth": "false", "time": "2025-05-18 13:25:01.145439", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 304, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 13:25:01.151382", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "mr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 306, "raw_pred": "A", "pred": "true", "ground_truth": "mostly false", "time": "2025-05-18 13:25:01.257087", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "az", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 309, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 13:25:01.282774", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 307, "raw_pred": "A", "pred": "true", "ground_truth": "false", "time": "2025-05-18 13:25:01.292270", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 308, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:25:01.297637", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 310, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 13:25:01.319200", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 311, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:25:01.423123", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "nl", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 312, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:25:01.450083", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 315, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:25:01.459551", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "si", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 314, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:25:01.460113", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "az", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 313, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 13:25:01.478768", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 316, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 13:25:01.603547", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 317, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:25:01.623592", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 318, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 13:25:01.641366", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 319, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "true", "time": "2025-05-18 13:25:01.645141", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 320, "raw_pred": "G", "pred": "false", "ground_truth": "mostly true", "time": "2025-05-18 13:25:01.654763", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 322, "raw_pred": "F", "pred": "mostly false", "ground_truth": "partly true/misleading", "time": "2025-05-18 13:25:01.763658", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "az", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 321, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 13:25:01.770738", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 325, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "true", "time": "2025-05-18 13:25:01.794971", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "nl", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 323, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 13:25:01.807508", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "mr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 324, "raw_pred": "G", "pred": "false", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 13:25:01.816794", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 328, "raw_pred": "G", "pred": "false", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 13:25:01.935632", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 326, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:25:01.942742", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 327, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 13:25:01.966666", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 329, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:25:01.974384", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "mr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 330, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:25:01.996303", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 331, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:25:02.103962", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 332, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:25:02.120743", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 334, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 13:25:02.139389", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 333, "raw_pred": "F", "pred": "mostly false", "ground_truth": "partly true/misleading", "time": "2025-05-18 13:25:02.141570", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 335, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:25:02.167579", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 337, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:25:02.265321", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 336, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 13:25:02.272211", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 339, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:25:02.321029", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 338, "raw_pred": "A", "pred": "true", "ground_truth": "false", "time": "2025-05-18 13:25:02.328863", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 340, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 13:25:02.329742", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 342, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 13:25:02.459994", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 341, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 13:25:02.460978", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 344, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 13:25:02.488205", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 343, "raw_pred": "G", "pred": "false", "ground_truth": "mostly true", "time": "2025-05-18 13:25:02.492054", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 345, "raw_pred": "G", "pred": "false", "ground_truth": "true", "time": "2025-05-18 13:25:02.493332", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 347, "raw_pred": "A", "pred": "true", "ground_truth": "false", "time": "2025-05-18 13:25:02.635740", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "az", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 346, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 13:25:02.640516", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 349, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 13:25:02.655331", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 350, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 13:25:02.670749", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "nl", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 348, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 13:25:02.692519", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "az", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 351, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:25:02.819010", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "mr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 352, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 13:25:02.845770", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 355, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:25:02.850492", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 354, "raw_pred": "F", "pred": "mostly false", "ground_truth": "partly true/misleading", "time": "2025-05-18 13:25:02.852354", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 353, "raw_pred": "A", "pred": "true", "ground_truth": "false", "time": "2025-05-18 13:25:02.863661", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "az", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 356, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:25:02.984521", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 359, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:25:03.037684", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 357, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:25:03.048610", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "az", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 358, "raw_pred": "D", "pred": "complicated/hard to categorise", "ground_truth": "partly true/misleading", "time": "2025-05-18 13:25:03.055596", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 360, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:25:03.057498", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 361, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:25:03.150452", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 362, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 13:25:03.184603", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 363, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:25:03.225875", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 365, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 13:25:03.229754", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "pa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 364, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 13:25:03.232896", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 366, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 13:25:03.296841", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 367, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 13:25:03.364052", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "pa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 368, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 13:25:03.391179", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "az", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 369, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 13:25:03.414955", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "gu", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 370, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 13:25:03.423087", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 371, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 13:25:03.456339", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "nl", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 372, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:25:03.525234", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "pa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 373, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:25:03.550950", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 374, "raw_pred": "D", "pred": "complicated/hard to categorise", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 13:25:03.573863", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "nl", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 375, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 13:25:03.594401", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "az", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 376, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:25:03.619896", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 377, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:25:03.689380", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 378, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 13:25:03.710374", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "gu", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 379, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:25:03.719652", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 380, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 13:25:03.750714", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 381, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "mostly false", "time": "2025-05-18 13:25:03.794370", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 382, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 13:25:03.837497", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 383, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:25:03.873487", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 384, "raw_pred": "D", "pred": "complicated/hard to categorise", "ground_truth": "true", "time": "2025-05-18 13:25:03.890706", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 385, "raw_pred": "D", "pred": "complicated/hard to categorise", "ground_truth": "other", "time": "2025-05-18 13:25:03.907644", "score": 0, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 386, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:25:03.951538", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 387, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 13:25:04.001771", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 388, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:25:04.038809", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 390, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:25:04.043620", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "nl", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 389, "raw_pred": "G", "pred": "false", "ground_truth": "true", "time": "2025-05-18 13:25:04.047596", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 391, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 13:25:04.135055", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "si", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 392, "raw_pred": "G", "pred": "false", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 13:25:04.162348", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 393, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 13:25:04.190975", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 395, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:25:04.219836", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 394, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 13:25:04.226088", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 396, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 13:25:04.292525", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "az", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 397, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 13:25:04.320160", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 399, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "partly true/misleading", "time": "2025-05-18 13:25:04.374655", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 398, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 13:25:04.377712", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 400, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:25:04.385544", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "nl", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 401, "raw_pred": "A", "pred": "true", "ground_truth": "false", "time": "2025-05-18 13:25:04.456177", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "az", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 402, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 13:25:04.503266", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 405, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 13:25:04.545472", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 404, "raw_pred": "A", "pred": "true", "ground_truth": "partly true/misleading", "time": "2025-05-18 13:25:04.560154", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "az", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 403, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 13:25:04.564070", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 406, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "partly true/misleading", "time": "2025-05-18 13:25:04.629435", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 407, "raw_pred": "F", "pred": "mostly false", "ground_truth": "partly true/misleading", "time": "2025-05-18 13:25:04.680181", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 408, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 13:25:04.706433", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 410, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "partly true/misleading", "time": "2025-05-18 13:25:04.740368", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 409, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 13:25:04.741497", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 411, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 13:25:04.788563", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 412, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:25:04.819276", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 413, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:25:04.886773", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "nl", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 415, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 13:25:04.911485", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 414, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 13:25:04.914532", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 416, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 13:25:04.972831", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "pa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 417, "raw_pred": "G", "pred": "false", "ground_truth": "true", "time": "2025-05-18 13:25:04.978029", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 418, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:25:05.060079", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "si", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 419, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 13:25:05.074311", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 420, "raw_pred": "G", "pred": "false", "ground_truth": "true", "time": "2025-05-18 13:25:05.084796", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 422, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:25:05.157352", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 421, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 13:25:05.160812", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 423, "raw_pred": "A", "pred": "true", "ground_truth": "true", "time": "2025-05-18 13:25:05.206246", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 425, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 13:25:05.246860", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 424, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:25:05.253136", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 427, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:25:05.337456", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 426, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 13:25:05.343862", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 428, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 13:25:05.361976", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 429, "raw_pred": "G", "pred": "false", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 13:25:05.412302", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 430, "raw_pred": "G", "pred": "false", "ground_truth": "other", "time": "2025-05-18 13:25:05.439714", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 431, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 13:25:05.501860", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "mr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 433, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:25:05.508220", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "mr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 432, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 13:25:05.524161", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 434, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 13:25:05.593751", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "mr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 435, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:25:05.599233", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 437, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 13:25:05.653353", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 436, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 13:25:05.680300", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "nl", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 438, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:25:05.689282", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 439, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:25:05.755484", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 440, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "mostly true", "time": "2025-05-18 13:25:05.765551", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 441, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 13:25:05.831606", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 442, "raw_pred": "B", "pred": "mostly true", "ground_truth": "true", "time": "2025-05-18 13:25:05.851443", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "az", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 443, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 13:25:05.867504", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 444, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:25:05.898438", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 445, "raw_pred": "G", "pred": "false", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 13:25:05.923484", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 446, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:25:05.987641", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "az", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 447, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 13:25:06.021590", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 448, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:25:06.048691", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "si", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 449, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:25:06.065301", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 450, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 13:25:06.082711", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 451, "raw_pred": "A", "pred": "true", "ground_truth": "partly true/misleading", "time": "2025-05-18 13:25:06.145925", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "mr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 452, "raw_pred": "G", "pred": "false", "ground_truth": "true", "time": "2025-05-18 13:25:06.177645", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "az", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 453, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 13:25:06.211829", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "si", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 454, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 13:25:06.221746", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 455, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 13:25:06.245617", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 456, "raw_pred": "G", "pred": "false", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 13:25:06.291667", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 457, "raw_pred": "G", "pred": "false", "ground_truth": "true", "time": "2025-05-18 13:25:06.313349", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 458, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 13:25:06.383045", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 459, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 13:25:06.390004", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "mr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 460, "raw_pred": "G", "pred": "false", "ground_truth": "other", "time": "2025-05-18 13:25:06.407975", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 461, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 13:25:06.445019", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 462, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:25:06.482087", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 463, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 13:25:06.534245", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "pa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 464, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:25:06.549211", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 465, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 13:25:06.567903", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 466, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:25:06.581907", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 467, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 13:25:06.647448", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "pa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 469, "raw_pred": "G", "pred": "false", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 13:25:06.692435", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 468, "raw_pred": "G", "pred": "false", "ground_truth": "other", "time": "2025-05-18 13:25:06.698210", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 471, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 13:25:06.742361", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 470, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 13:25:06.753456", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "nl", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 472, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:25:06.809444", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "gu", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 474, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:25:06.865615", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 473, "raw_pred": "A", "pred": "true", "ground_truth": "false", "time": "2025-05-18 13:25:06.871503", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 475, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:25:06.906952", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 476, "raw_pred": "D", "pred": "complicated/hard to categorise", "ground_truth": "false", "time": "2025-05-18 13:25:06.916470", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 477, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:25:06.971619", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 479, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:25:07.021898", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "nl", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 478, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 13:25:07.032646", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 480, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:25:07.066239", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "nl", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 481, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:25:07.091739", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 482, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 13:25:07.118704", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 484, "raw_pred": "G", "pred": "false", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 13:25:07.191915", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 485, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:25:07.215685", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "pa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 483, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "true", "time": "2025-05-18 13:25:07.225297", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 486, "raw_pred": "D", "pred": "complicated/hard to categorise", "ground_truth": "false", "time": "2025-05-18 13:25:07.244870", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 487, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 13:25:07.279944", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "pa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 490, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:25:07.363475", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 488, "raw_pred": "G", "pred": "false", "ground_truth": "true", "time": "2025-05-18 13:25:07.367062", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 489, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 13:25:07.383612", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 491, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:25:07.410147", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "az", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 492, "raw_pred": "F", "pred": "mostly false", "ground_truth": "mostly false", "time": "2025-05-18 13:25:07.437153", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "az", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 493, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:25:07.512442", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 496, "raw_pred": "G", "pred": "false", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 13:25:07.542308", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 494, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 13:25:07.546646", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "pa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 495, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 13:25:07.561109", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "si", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 497, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 13:25:07.601180", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 498, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 13:25:07.687181", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 499, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 13:25:07.717400", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
