{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4c28884-595a-4752-b1b2-fbfd0512310a",
   "metadata": {},
   "source": [
    "# Load Dataset\n",
    "\n",
    "Sample code using Pandas to load datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "209efd00-e178-43ad-b0cc-0c6208f8a892",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1dd694-8344-4e7a-b3c0-b64e04c9d0a2",
   "metadata": {},
   "source": [
    "### X-Fact Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe8b8ba3-345f-44e5-b847-e152045d1a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x_fact = pd.read_csv(\"../data/x_fact_dataset/x-fact-including-en/train.all.tsv\", delimiter=\"\\t\", on_bad_lines=\"skip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ec29546-554d-4d28-b082-e4fc9f12e5c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>site</th>\n",
       "      <th>evidence_1</th>\n",
       "      <th>evidence_2</th>\n",
       "      <th>evidence_3</th>\n",
       "      <th>evidence_4</th>\n",
       "      <th>evidence_5</th>\n",
       "      <th>link_1</th>\n",
       "      <th>link_2</th>\n",
       "      <th>link_3</th>\n",
       "      <th>link_4</th>\n",
       "      <th>link_5</th>\n",
       "      <th>claimDate</th>\n",
       "      <th>reviewDate</th>\n",
       "      <th>claimant</th>\n",
       "      <th>claim</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tr</td>\n",
       "      <td>dogrulukpayi.com</td>\n",
       "      <td>Son 50 yılın siyasi tarihine bakın, tek başına...</td>\n",
       "      <td>Son 50 yılın siyasi tarihine bakın, tek başına...</td>\n",
       "      <td>Türkiye potansiyelini doğru kullanıp yüzde 7 b...</td>\n",
       "      <td>2020/01/02 — Türkiye Cumhuriyeti tarihinde hiç...</td>\n",
       "      <td>2002/12/09 — Cumhuriyet tarihi boyunca tek par...</td>\n",
       "      <td>https://www.dogrulukpayi.com/iddia-kontrolu/so...</td>\n",
       "      <td>https://www.dogrulukpayi.com/yazar/furkan-demi...</td>\n",
       "      <td>https://businessht.bloomberght.com/yazarlar/ca...</td>\n",
       "      <td>https://www.mahfiegilmez.com/2020/01/turkiye-e...</td>\n",
       "      <td>https://www.hurriyet.com.tr/ekonomi/tek-parti-...</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>Binali  Yıldırım</td>\n",
       "      <td>Son 50 yılın siyasi tarihine bakın, tek başına...</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ka</td>\n",
       "      <td>factcheck.ge</td>\n",
       "      <td>Oct 4, 2018 — იტალიის სამაშველო სამსახურებს მი...</td>\n",
       "      <td>ევროპული ღირებულებები - იტალიის სამაშველო სამს...</td>\n",
       "      <td>ევროპული ღირებულებები - იტალიის სამაშველო სამს...</td>\n",
       "      <td>&lt;DUMMY_EVIDENCE&gt;</td>\n",
       "      <td>&lt;DUMMY_EVIDENCE&gt;</td>\n",
       "      <td>https://factcheck.ge/ka/story/37352-evropuli-g...</td>\n",
       "      <td>https://factcheck.ge/ka/page/persons/thbilisi-24</td>\n",
       "      <td>http://142.93.167.204/ka/page/persons/thbilisi-24</td>\n",
       "      <td>NO_LINK</td>\n",
       "      <td>NO_LINK</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>თბილისი 24</td>\n",
       "      <td>ევროპული ღირებულებები - იტალიის სამაშველო სამს...</td>\n",
       "      <td>partly true/misleading</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pt</td>\n",
       "      <td>piaui.folha.uol.com.br</td>\n",
       "      <td>03.11.2020 — “Aqui em São Paulo, nós estamos c...</td>\n",
       "      <td>03.11.2020 — ... França erra sobre creches, mo...</td>\n",
       "      <td>05.06.2020 — A lei aprovada pelo Congresso que...</td>\n",
       "      <td>Caixa paga auxílio emergencial de R$ 600 e R$ ...</td>\n",
       "      <td>7 de julho de 2020, 15:20h ... Porém, diferent...</td>\n",
       "      <td>https://piaui.folha.uol.com.br/lupa/2020/11/03...</td>\n",
       "      <td>https://www1.folha.uol.com.br/poder/2020/11/na...</td>\n",
       "      <td>https://g1.globo.com/economia/noticia/2020/06/...</td>\n",
       "      <td>https://jc.ne10.uol.com.br/economia/2020/11/11...</td>\n",
       "      <td>https://noticiasconcursos.com.br/direitos-trab...</td>\n",
       "      <td>2020-11-03T12:41:12Z</td>\n",
       "      <td>2020-11-03T12:41:12Z</td>\n",
       "      <td>Márcio França (PSB)</td>\n",
       "      <td>Aqui em São Paulo, nós estamos com 2,7 milhões...</td>\n",
       "      <td>partly true/misleading</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ka</td>\n",
       "      <td>factcheck.ge</td>\n",
       "      <td>Sep 12, 2016 — ირაკლი ხახუბია, \"ნაციონალური მო...</td>\n",
       "      <td>ირაკლი ხახუბია, \"ნაციონალური მოძრაობის\" სპონსო...</td>\n",
       "      <td>ირაკლი ხახუბია, \"ნაციონალური მოძრაობის\" სპონსო...</td>\n",
       "      <td>ირაკლი ხახუბია, \"ნაციონალური მოძრაობის\" სპონსო...</td>\n",
       "      <td>&lt;DUMMY_EVIDENCE&gt;</td>\n",
       "      <td>https://factcheck.ge/ka/story/23935-irakli-kha...</td>\n",
       "      <td>https://factcheck.ge/ka/stories/archive?page=128</td>\n",
       "      <td>http://142.93.167.204/ka/stories/archive?page=140</td>\n",
       "      <td>http://142.93.167.204/ka/topics/%E1%83%9E%E1%8...</td>\n",
       "      <td>NO_LINK</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>შალვა ნათელაშვილი</td>\n",
       "      <td>ირაკლი ხახუბია, \"ნაციონალური მოძრაობის\" სპონსო...</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id</td>\n",
       "      <td>cekfakta.com</td>\n",
       "      <td>Sep 18, 2018 — Akun @lambeturah memposting seb...</td>\n",
       "      <td>[SALAH] Zumi Zola Jalan-Jalan Di Bandara Soeka...</td>\n",
       "      <td>[DISINFORMASI] Zumi Zola Jalan-Jalan Di Bandar...</td>\n",
       "      <td>Sep 17, 2018 — JAKARTA, KOMPAS.com - Pengacara...</td>\n",
       "      <td>Sep 17, 2018 — Jakarta, CNN Indonesia -- Sebua...</td>\n",
       "      <td>https://turnbackhoax.id/2018/09/18/salah-zumi-...</td>\n",
       "      <td>https://ru-ru.facebook.com/groups/fafhh/permal...</td>\n",
       "      <td>https://cekfakta.com/focus/459</td>\n",
       "      <td>https://nasional.kompas.com/read/2018/09/17/10...</td>\n",
       "      <td>https://www.cnnindonesia.com/nasional/20180917...</td>\n",
       "      <td>none</td>\n",
       "      <td>2018-09-18T00:00:00Z</td>\n",
       "      <td>none</td>\n",
       "      <td>Zumi Zola Jalan-Jalan Di Bandara Soekarno-Hatta</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  language                    site  \\\n",
       "0       tr        dogrulukpayi.com   \n",
       "1       ka            factcheck.ge   \n",
       "2       pt  piaui.folha.uol.com.br   \n",
       "3       ka            factcheck.ge   \n",
       "4       id            cekfakta.com   \n",
       "\n",
       "                                          evidence_1  \\\n",
       "0  Son 50 yılın siyasi tarihine bakın, tek başına...   \n",
       "1  Oct 4, 2018 — იტალიის სამაშველო სამსახურებს მი...   \n",
       "2  03.11.2020 — “Aqui em São Paulo, nós estamos c...   \n",
       "3  Sep 12, 2016 — ირაკლი ხახუბია, \"ნაციონალური მო...   \n",
       "4  Sep 18, 2018 — Akun @lambeturah memposting seb...   \n",
       "\n",
       "                                          evidence_2  \\\n",
       "0  Son 50 yılın siyasi tarihine bakın, tek başına...   \n",
       "1  ევროპული ღირებულებები - იტალიის სამაშველო სამს...   \n",
       "2  03.11.2020 — ... França erra sobre creches, mo...   \n",
       "3  ირაკლი ხახუბია, \"ნაციონალური მოძრაობის\" სპონსო...   \n",
       "4  [SALAH] Zumi Zola Jalan-Jalan Di Bandara Soeka...   \n",
       "\n",
       "                                          evidence_3  \\\n",
       "0  Türkiye potansiyelini doğru kullanıp yüzde 7 b...   \n",
       "1  ევროპული ღირებულებები - იტალიის სამაშველო სამს...   \n",
       "2  05.06.2020 — A lei aprovada pelo Congresso que...   \n",
       "3  ირაკლი ხახუბია, \"ნაციონალური მოძრაობის\" სპონსო...   \n",
       "4  [DISINFORMASI] Zumi Zola Jalan-Jalan Di Bandar...   \n",
       "\n",
       "                                          evidence_4  \\\n",
       "0  2020/01/02 — Türkiye Cumhuriyeti tarihinde hiç...   \n",
       "1                                   <DUMMY_EVIDENCE>   \n",
       "2  Caixa paga auxílio emergencial de R$ 600 e R$ ...   \n",
       "3  ირაკლი ხახუბია, \"ნაციონალური მოძრაობის\" სპონსო...   \n",
       "4  Sep 17, 2018 — JAKARTA, KOMPAS.com - Pengacara...   \n",
       "\n",
       "                                          evidence_5  \\\n",
       "0  2002/12/09 — Cumhuriyet tarihi boyunca tek par...   \n",
       "1                                   <DUMMY_EVIDENCE>   \n",
       "2  7 de julho de 2020, 15:20h ... Porém, diferent...   \n",
       "3                                   <DUMMY_EVIDENCE>   \n",
       "4  Sep 17, 2018 — Jakarta, CNN Indonesia -- Sebua...   \n",
       "\n",
       "                                              link_1  \\\n",
       "0  https://www.dogrulukpayi.com/iddia-kontrolu/so...   \n",
       "1  https://factcheck.ge/ka/story/37352-evropuli-g...   \n",
       "2  https://piaui.folha.uol.com.br/lupa/2020/11/03...   \n",
       "3  https://factcheck.ge/ka/story/23935-irakli-kha...   \n",
       "4  https://turnbackhoax.id/2018/09/18/salah-zumi-...   \n",
       "\n",
       "                                              link_2  \\\n",
       "0  https://www.dogrulukpayi.com/yazar/furkan-demi...   \n",
       "1   https://factcheck.ge/ka/page/persons/thbilisi-24   \n",
       "2  https://www1.folha.uol.com.br/poder/2020/11/na...   \n",
       "3   https://factcheck.ge/ka/stories/archive?page=128   \n",
       "4  https://ru-ru.facebook.com/groups/fafhh/permal...   \n",
       "\n",
       "                                              link_3  \\\n",
       "0  https://businessht.bloomberght.com/yazarlar/ca...   \n",
       "1  http://142.93.167.204/ka/page/persons/thbilisi-24   \n",
       "2  https://g1.globo.com/economia/noticia/2020/06/...   \n",
       "3  http://142.93.167.204/ka/stories/archive?page=140   \n",
       "4                     https://cekfakta.com/focus/459   \n",
       "\n",
       "                                              link_4  \\\n",
       "0  https://www.mahfiegilmez.com/2020/01/turkiye-e...   \n",
       "1                                            NO_LINK   \n",
       "2  https://jc.ne10.uol.com.br/economia/2020/11/11...   \n",
       "3  http://142.93.167.204/ka/topics/%E1%83%9E%E1%8...   \n",
       "4  https://nasional.kompas.com/read/2018/09/17/10...   \n",
       "\n",
       "                                              link_5             claimDate  \\\n",
       "0  https://www.hurriyet.com.tr/ekonomi/tek-parti-...                  none   \n",
       "1                                            NO_LINK                  none   \n",
       "2  https://noticiasconcursos.com.br/direitos-trab...  2020-11-03T12:41:12Z   \n",
       "3                                            NO_LINK                  none   \n",
       "4  https://www.cnnindonesia.com/nasional/20180917...                  none   \n",
       "\n",
       "             reviewDate             claimant  \\\n",
       "0                  none     Binali  Yıldırım   \n",
       "1                  none           თბილისი 24   \n",
       "2  2020-11-03T12:41:12Z  Márcio França (PSB)   \n",
       "3                  none    შალვა ნათელაშვილი   \n",
       "4  2018-09-18T00:00:00Z                 none   \n",
       "\n",
       "                                               claim                   label  \n",
       "0  Son 50 yılın siyasi tarihine bakın, tek başına...                   false  \n",
       "1  ევროპული ღირებულებები - იტალიის სამაშველო სამს...  partly true/misleading  \n",
       "2  Aqui em São Paulo, nós estamos com 2,7 milhões...  partly true/misleading  \n",
       "3  ირაკლი ხახუბია, \"ნაციონალური მოძრაობის\" სპონსო...                    true  \n",
       "4    Zumi Zola Jalan-Jalan Di Bandara Soekarno-Hatta                   false  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_x_fact.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a346d1e-7a3b-492b-9527-2071b0f149e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30492,)\n"
     ]
    }
   ],
   "source": [
    "x_fact_claims = df_x_fact[\"claim\"].values\n",
    "print(x_fact_claims.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54361874-e400-4f2b-bf11-2f6fe74c0c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30492,)\n"
     ]
    }
   ],
   "source": [
    "x_fact_labels = df_x_fact[\"label\"].values\n",
    "print(x_fact_claims.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3dbb4116-9254-4c35-8ebe-407a86830f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_prompt_1(STATEMENT):\n",
    "    return f\"Rate the truthfulness of the following statement: “{STATEMENT}” Provide a score from 0 to 100, where 0 represents definitively false and 100 represents definitively true. Do not provide any explanations, only respond with the numerical score.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29f1e7e6-7742-4a58-99e5-7bde0b6bfe52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_prompt_2(STATEMENT):\n",
    "    return f\"Rate the truthfulness of the following statement: “{STATEMENT}” Provide a number 0 or 1, where 0 represents false and 1 represents true. Do not provide any explanations, only respond with the number.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2caf731d-7a8a-49cc-a29a-465156e6700f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate the truthfulness of the following statement: “Son 50 yılın siyasi tarihine bakın, tek başına iktidarlardaki Türkiye’nin büyüme oranı, koalisyon dönemlerindekinin iki katıdır.” Provide a score from 0 to 100, where 0 represents definitively false and 100 represents definitively true. Do not provide any explanations, only respond with the numerical score.\n"
     ]
    }
   ],
   "source": [
    "print(return_prompt_1(df_x_fact[\"claim\"][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65b03c87-9646-481e-9c25-c72e89f3fd5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate the truthfulness of the following statement: “Son 50 yılın siyasi tarihine bakın, tek başına iktidarlardaki Türkiye’nin büyüme oranı, koalisyon dönemlerindekinin iki katıdır.” Provide a number 0 or 1, where 0 represents false and 1 represents true. Do not provide any explanations, only respond with the number.\n"
     ]
    }
   ],
   "source": [
    "print(return_prompt_2(df_x_fact[\"claim\"][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f667ac-db75-41ea-b4dc-b5a7b0f4959b",
   "metadata": {},
   "source": [
    "Running the eval on https://console.cloud.google.com/vertex-ai/generative/language/create/text?project=llm-misinfo-eval (Vertex AI from Google), with temperature=0.\n",
    "\n",
    "Using the first prompt from Kellin's paper:\n",
    "\n",
    "`Rate the truthfulness\r\n",
    "of the following statement: “STATEMENT” Provide a score from 0 to 100, where 0 represents\r\n",
    "definitively false and 100 represents definitively\r\n",
    "true. Do not provide any explanations, only respond with the numerical sc`ore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "04041658-e694-407e-b3d3-370c26643c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import vertexai\n",
    "from vertexai.language_models import TextGenerationModel\n",
    "from vertexai.preview.generative_models import GenerativeModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f9d05359-091f-489d-8b8b-009a1c52bfd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_model(prompt):\n",
    "    vertexai.init(project='llm-misinfo-eval', location='us-central1')\n",
    "    parameters = {\n",
    "        # 'temperature':0,\n",
    "        # 'max_output_tokens':256,\n",
    "        # 'top_p':0.8,\n",
    "        # 'top_k':40\n",
    "    }\n",
    "    model = GenerativeModel('gemini-1.0-pro')\n",
    "    resp = model.generate_content(prompt, **parameters)\n",
    "    return resp\n",
    "\n",
    "def get_text_resp(model_resp):\n",
    "    return model_resp.candidates[0].content.parts[0].text\n",
    "# resp = get_text_resp(call_model('what is your name?'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "39716734-5eff-40ca-89a3-c11a0b5da20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "resp  = call_model('what is your name?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "12d60134-3633-49f4-80e6-43fe6f063e50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[content {\n",
       "   role: \"model\"\n",
       "   parts {\n",
       "     text: \"I am Gemini, a multimodal AI language model developed by Google. I don\\'t have a name, as I am not a person.\"\n",
       "   }\n",
       " }\n",
       " finish_reason: STOP\n",
       " safety_ratings {\n",
       "   category: HARM_CATEGORY_HATE_SPEECH\n",
       "   probability: NEGLIGIBLE\n",
       " }\n",
       " safety_ratings {\n",
       "   category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
       "   probability: NEGLIGIBLE\n",
       " }\n",
       " safety_ratings {\n",
       "   category: HARM_CATEGORY_HARASSMENT\n",
       "   probability: NEGLIGIBLE\n",
       " }\n",
       " safety_ratings {\n",
       "   category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
       "   probability: NEGLIGIBLE\n",
       " }]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp.candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1b6e3196-5a3a-4520-8bbd-b0ab2a0e4e95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I am Gemini, a multimodal AI language model developed by Google. I don't have a name, as I am not a person.\""
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_text_resp(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7eb49dd7-5d8b-48ff-afbc-81cfd3243718",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [15:10<00:00, 18.21s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import trange\n",
    "import time\n",
    "df_results_prompt_1_list = []\n",
    "for i in trange(50):\n",
    "    tmp = {'modelResp':None, 'trueLabel':df_x_fact['label'][i]}\n",
    "    claim = df_x_fact['claim'][i]\n",
    "    prompt = return_prompt_1(claim)\n",
    "    model_resp = call_model(prompt)\n",
    "    model_text_resp = get_text_resp(model_resp)\n",
    "    try:\n",
    "        tmp['modelResp'] = float(model_text_resp)\n",
    "    except:\n",
    "        tmp['modelResp'] = float(model_text_resp)\n",
    "    df_results_prompt_1_list.append(tmp)\n",
    "    time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "49447e14-3b6a-43da-ac06-9d3f6cd7faaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modelResp</th>\n",
       "      <th>trueLabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60.0</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70.0</td>\n",
       "      <td>partly true/misleading</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50.0</td>\n",
       "      <td>partly true/misleading</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50.0</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   modelResp               trueLabel\n",
       "0       60.0                   false\n",
       "1       70.0  partly true/misleading\n",
       "2       50.0  partly true/misleading\n",
       "3       50.0                    true\n",
       "4        0.0                   false"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results_prompt_1 = pd.DataFrame(df_results_prompt_1_list)\n",
    "df_results_prompt_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c9fbd539-6814-4682-9012-03587204032f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    modelResp               trueLabel\n",
      "0        60.0                   false\n",
      "1        70.0  partly true/misleading\n",
      "2        50.0  partly true/misleading\n",
      "3        50.0                    true\n",
      "4         0.0                   false\n",
      "5         0.0             mostly true\n",
      "6        50.0                    true\n",
      "7        50.0             mostly true\n",
      "8         0.0  partly true/misleading\n",
      "9        80.0                   false\n",
      "10       50.0            mostly false\n",
      "11        0.0                   false\n",
      "12       50.0  partly true/misleading\n",
      "13      100.0                    true\n",
      "14       30.0  partly true/misleading\n",
      "15       60.0                    true\n",
      "16       50.0            mostly false\n",
      "17        0.0                   false\n",
      "18       60.0             mostly true\n",
      "19       50.0                   false\n",
      "20        0.0             mostly true\n",
      "21       60.0  partly true/misleading\n",
      "22        0.0                   false\n",
      "23       50.0                   false\n",
      "24       70.0                    true\n",
      "25        0.0  partly true/misleading\n",
      "26        0.0                   false\n",
      "27        0.0  partly true/misleading\n",
      "28       50.0  partly true/misleading\n",
      "29       70.0             mostly true\n",
      "30       70.0                   false\n",
      "31       60.0  partly true/misleading\n",
      "32        0.0  partly true/misleading\n",
      "33       60.0  partly true/misleading\n",
      "34        0.0                    true\n",
      "35      100.0                    true\n",
      "36       50.0                    true\n",
      "37        0.0                    true\n",
      "38        0.0  partly true/misleading\n",
      "39       75.0  partly true/misleading\n",
      "40        0.0                   false\n",
      "41        0.0  partly true/misleading\n",
      "42       60.0                    true\n",
      "43       60.0                    true\n",
      "44        0.0                   false\n",
      "45        0.0                   false\n",
      "46       50.0                    true\n",
      "47        0.0             mostly true\n",
      "48        0.0                   false\n",
      "49        0.0                   false\n"
     ]
    }
   ],
   "source": [
    "print(df_results_prompt_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "842ef19b-21ca-4ceb-94cb-88adaa7cbab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.74      0.78        38\n",
      "           1       0.38      0.50      0.43        12\n",
      "\n",
      "    accuracy                           0.68        50\n",
      "   macro avg       0.60      0.62      0.60        50\n",
      "weighted avg       0.72      0.68      0.69        50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_true_binary = []\n",
    "for i in range(50):\n",
    "    if df_x_fact['label'][i] == 'true':\n",
    "        y_true_binary.append(1)\n",
    "    else:\n",
    "        y_true_binary.append(0)\n",
    "y_pred_binary_prompt_1 = []\n",
    "\n",
    "for i in range(df_results_prompt_1.shape[0]):\n",
    "    if df_results_prompt_1['modelResp'][i] > 50:\n",
    "        y_pred_binary_prompt_1.append(1)\n",
    "    else:\n",
    "        y_pred_binary_prompt_1.append(0)\n",
    "print(classification_report(y_true_binary, y_pred_binary_prompt_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f151b87a-d572-4aa5-aeba-1ffb5565c3c6",
   "metadata": {},
   "source": [
    "### Mumin Trawl Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "571baa87-830e-4f81-8035-0117befc8b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mumin = pd.read_csv(\"../data/mumin_trawl_dataset/verdict_annotations.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f65f3a09-e00c-4bd1-b071-49f57a7206d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>verdict</th>\n",
       "      <th>claim</th>\n",
       "      <th>date</th>\n",
       "      <th>source</th>\n",
       "      <th>reviewer</th>\n",
       "      <th>language</th>\n",
       "      <th>raw_verdict</th>\n",
       "      <th>raw_verdict_en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>misinformation</td>\n",
       "      <td>Uma suposta citação de Albert Einstein diz que...</td>\n",
       "      <td>2019-03-28T19:22:09Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>poligrafo.sapo.pt</td>\n",
       "      <td>pt</td>\n",
       "      <td>Pimenta na Língua</td>\n",
       "      <td>Pepper on the tongue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>misinformation</td>\n",
       "      <td>İskoçya'dan Türkiye'ye uzanan 12 bin yıllık gi...</td>\n",
       "      <td>2017-06-03T00:00:00Z</td>\n",
       "      <td>Biliyomuydun</td>\n",
       "      <td>teyit.org</td>\n",
       "      <td>tr</td>\n",
       "      <td>Karma</td>\n",
       "      <td>Karma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>misinformation</td>\n",
       "      <td>Une analyse anti-Macron de Natacha Polony</td>\n",
       "      <td>2020-06-09T00:00:00Z</td>\n",
       "      <td>Sources multiples</td>\n",
       "      <td>factuel.afp.com</td>\n",
       "      <td>fr</td>\n",
       "      <td>Attention</td>\n",
       "      <td>Attention</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>misinformation</td>\n",
       "      <td>W Polsce zmarło 1670 osób zaszczepionych przec...</td>\n",
       "      <td>2021-04-15T00:00:00Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sprawdzam.afp.com</td>\n",
       "      <td>pl</td>\n",
       "      <td>Brakujący kontekst</td>\n",
       "      <td>Missing context</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>misinformation</td>\n",
       "      <td>مدينة البدقية على شكل قلب</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>verify-sy.com</td>\n",
       "      <td>ar</td>\n",
       "      <td>Mostly false</td>\n",
       "      <td>Mostly false</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          verdict                                              claim  \\\n",
       "0  misinformation  Uma suposta citação de Albert Einstein diz que...   \n",
       "1  misinformation  İskoçya'dan Türkiye'ye uzanan 12 bin yıllık gi...   \n",
       "2  misinformation          Une analyse anti-Macron de Natacha Polony   \n",
       "3  misinformation  W Polsce zmarło 1670 osób zaszczepionych przec...   \n",
       "4  misinformation                          مدينة البدقية على شكل قلب   \n",
       "\n",
       "                   date             source           reviewer language  \\\n",
       "0  2019-03-28T19:22:09Z                NaN  poligrafo.sapo.pt       pt   \n",
       "1  2017-06-03T00:00:00Z       Biliyomuydun          teyit.org       tr   \n",
       "2  2020-06-09T00:00:00Z  Sources multiples    factuel.afp.com       fr   \n",
       "3  2021-04-15T00:00:00Z                NaN  sprawdzam.afp.com       pl   \n",
       "4                   NaN                NaN      verify-sy.com       ar   \n",
       "\n",
       "          raw_verdict        raw_verdict_en  \n",
       "0   Pimenta na Língua  Pepper on the tongue  \n",
       "1               Karma                 Karma  \n",
       "2           Attention             Attention  \n",
       "3  Brakujący kontekst       Missing context  \n",
       "4        Mostly false          Mostly false  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mumin.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b85d6141-e541-4042-b929-d857f965c23b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(906,)\n"
     ]
    }
   ],
   "source": [
    "mumin_claims = df_mumin[\"claim\"].values\n",
    "print(mumin_claims.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9c0c2b39-bc75-4b26-a639-125e1ffa69e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(906,)\n"
     ]
    }
   ],
   "source": [
    "mumin_labels = df_mumin[\"verdict\"].values\n",
    "print(mumin_labels.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
