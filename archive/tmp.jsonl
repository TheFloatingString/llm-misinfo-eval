{"dataset": "x-fact-in-domain", "idx_after_dropna": 1, "raw_pred": "D", "pred": "complicated/hard to categorise", "ground_truth": "false", "time": "2025-05-18 00:28:10.419576", "score": 0.5, "model": "o4-mini", "provider": "openai", "language": "pt", "prompt_type": "mcq"}
{"dataset": "x-fact-in-domain", "idx_after_dropna": 2, "raw_pred": "D", "pred": "complicated/hard to categorise", "ground_truth": "false", "time": "2025-05-18 00:28:10.451963", "score": 0.5, "model": "o4-mini", "provider": "openai", "language": "pt", "prompt_type": "mcq"}
{"dataset": "x-fact-in-domain", "idx_after_dropna": 6, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 00:28:13.011727", "score": 1.0, "model": "o4-mini", "provider": "openai", "language": "ta", "prompt_type": "mcq"}
{"dataset": "x-fact-in-domain", "idx_after_dropna": 4, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 00:28:13.566039", "score": 0.25, "model": "o4-mini", "provider": "openai", "language": "pt", "prompt_type": "mcq"}
{"dataset": "x-fact-in-domain", "idx_after_dropna": 0, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 00:28:14.347831", "score": 1.0, "model": "o4-mini", "provider": "openai", "language": "pt", "prompt_type": "mcq"}
{"dataset": "x-fact-in-domain", "idx_after_dropna": 5, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "mostly true", "time": "2025-05-18 00:28:15.588728", "score": 0.75, "model": "o4-mini", "provider": "openai", "language": "ka", "prompt_type": "mcq"}
{"dataset": "x-fact-in-domain", "idx_after_dropna": 8, "raw_pred": "D", "pred": "complicated/hard to categorise", "ground_truth": "false", "time": "2025-05-18 00:28:15.978028", "score": 0.5, "model": "o4-mini", "provider": "openai", "language": "pt", "prompt_type": "mcq"}
{"dataset": "x-fact-in-domain", "idx_after_dropna": 11, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 00:28:18.745203", "score": 1.0, "model": "o4-mini", "provider": "openai", "language": "ar", "prompt_type": "mcq"}
{"dataset": "x-fact-in-domain", "idx_after_dropna": 9, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 00:28:19.013357", "score": 1.0, "model": "o4-mini", "provider": "openai", "language": "ta", "prompt_type": "mcq"}
{"dataset": "x-fact-in-domain", "idx_after_dropna": 10, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 00:28:19.774132", "score": 0.25, "model": "o4-mini", "provider": "openai", "language": "ar", "prompt_type": "mcq"}
{"dataset": "x-fact-in-domain", "idx_after_dropna": 12, "raw_pred": "E", "pred": "other", "ground_truth": "true", "time": "2025-05-18 00:28:22.123506", "score": 0.0, "model": "o4-mini", "provider": "openai", "language": "pt", "prompt_type": "mcq"}
{"dataset": "x-fact-in-domain", "idx_after_dropna": 14, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 00:28:22.146712", "score": 0.25, "model": "o4-mini", "provider": "openai", "language": "id", "prompt_type": "mcq"}
{"dataset": "x-fact-in-domain", "idx_after_dropna": 7, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "true", "time": "2025-05-18 00:28:23.894377", "score": 0.5, "model": "o4-mini", "provider": "openai", "language": "tr", "prompt_type": "mcq"}
{"dataset": "x-fact-in-domain", "idx_after_dropna": 16, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 00:28:25.094119", "score": 0.5, "model": "o4-mini", "provider": "openai", "language": "pt", "prompt_type": "mcq"}
{"dataset": "x-fact-in-domain", "idx_after_dropna": 3, "raw_pred": "G", "pred": "false", "ground_truth": "true", "time": "2025-05-18 00:28:29.399820", "score": 0.0, "model": "o4-mini", "provider": "openai", "language": "pt", "prompt_type": "mcq"}
{"dataset": "x-fact-in-domain", "idx_after_dropna": 17, "raw_pred": "A", "pred": "true", "ground_truth": "false", "time": "2025-05-18 00:28:30.164825", "score": 0.0, "model": "o4-mini", "provider": "openai", "language": "id", "prompt_type": "mcq"}
{"dataset": "x-fact-in-domain", "idx_after_dropna": 18, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 00:28:31.064936", "score": 1.0, "model": "o4-mini", "provider": "openai", "language": "id", "prompt_type": "mcq"}
{"dataset": "x-fact-in-domain", "idx_after_dropna": 6, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 00:32:45.293192", "score": 1.0, "model": "o4-mini", "provider": "openai", "language": "ta", "prompt_type": "mcq"}
{"dataset": "x-fact-in-domain", "idx_after_dropna": 8, "raw_pred": "D", "pred": "complicated/hard to categorise", "ground_truth": "false", "time": "2025-05-18 00:32:47.656604", "score": 0.5, "model": "o4-mini", "provider": "openai", "language": "pt", "prompt_type": "mcq"}
{"dataset": "x-fact-in-domain", "idx_after_dropna": 1, "raw_pred": "D", "pred": "complicated/hard to categorise", "ground_truth": "false", "time": "2025-05-18 00:32:47.657771", "score": 0.5, "model": "o4-mini", "provider": "openai", "language": "pt", "prompt_type": "mcq"}
{"dataset": "x-fact-in-domain", "idx_after_dropna": 7, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "true", "time": "2025-05-18 00:32:48.165320", "score": 0.5, "model": "o4-mini", "provider": "openai", "language": "tr", "prompt_type": "mcq"}
{"dataset": "x-fact-in-domain", "idx_after_dropna": 10, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 00:32:48.178848", "score": 0.25, "model": "o4-mini", "provider": "openai", "language": "ar", "prompt_type": "mcq"}
{"dataset": "x-fact-in-domain", "idx_after_dropna": 5, "raw_pred": "D", "pred": "complicated/hard to categorise", "ground_truth": "mostly true", "time": "2025-05-18 00:32:48.777647", "score": 0.0, "model": "o4-mini", "provider": "openai", "language": "ka", "prompt_type": "mcq"}
{"dataset": "x-fact-in-domain", "idx_after_dropna": 9, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 00:32:49.093643", "score": 1.0, "model": "o4-mini", "provider": "openai", "language": "ta", "prompt_type": "mcq"}
{"dataset": "x-fact-in-domain", "idx_after_dropna": 2, "raw_pred": "D", "pred": "complicated/hard to categorise", "ground_truth": "false", "time": "2025-05-18 00:32:49.337142", "score": 0.5, "model": "o4-mini", "provider": "openai", "language": "pt", "prompt_type": "mcq"}
{"dataset": "x-fact-in-domain", "idx_after_dropna": 11, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 00:32:49.672039", "score": 1.0, "model": "o4-mini", "provider": "openai", "language": "ar", "prompt_type": "mcq"}
{"dataset": "x-fact-in-domain", "idx_after_dropna": 14, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 00:32:50.605421", "score": 0.25, "model": "o4-mini", "provider": "openai", "language": "id", "prompt_type": "mcq"}
{"dataset": "x-fact-in-domain", "idx_after_dropna": 3, "raw_pred": "G", "pred": "false", "ground_truth": "true", "time": "2025-05-18 00:32:50.690590", "score": 0.0, "model": "o4-mini", "provider": "openai", "language": "pt", "prompt_type": "mcq"}
{"dataset": "x-fact-in-domain", "idx_after_dropna": 17, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 00:32:51.496766", "score": 1.0, "model": "o4-mini", "provider": "openai", "language": "id", "prompt_type": "mcq"}
{"dataset": "x-fact-in-domain", "idx_after_dropna": 12, "raw_pred": "E", "pred": "other", "ground_truth": "true", "time": "2025-05-18 00:32:51.951909", "score": 0.0, "model": "o4-mini", "provider": "openai", "language": "pt", "prompt_type": "mcq"}
{"dataset": "x-fact-in-domain", "idx_after_dropna": 4, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 00:32:52.772909", "score": 0.25, "model": "o4-mini", "provider": "openai", "language": "pt", "prompt_type": "mcq"}
{"dataset": "x-fact-in-domain", "idx_after_dropna": 16, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 00:32:53.641058", "score": 1.0, "model": "o4-mini", "provider": "openai", "language": "pt", "prompt_type": "mcq"}
{"dataset": "x-fact-in-domain", "idx_after_dropna": 19, "raw_pred": "G", "pred": "false", "ground_truth": "true", "time": "2025-05-18 00:32:54.108546", "score": 0.0, "model": "o4-mini", "provider": "openai", "language": "de", "prompt_type": "mcq"}
{"dataset": "x-fact-in-domain", "idx_after_dropna": 18, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 00:32:55.847584", "score": 1.0, "model": "o4-mini", "provider": "openai", "language": "id", "prompt_type": "mcq"}
{"dataset": "x-fact-in-domain", "idx_after_dropna": 21, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 00:32:57.483591", "score": 0.25, "model": "o4-mini", "provider": "openai", "language": "ta", "prompt_type": "mcq"}
{"dataset": "x-fact-in-domain", "idx_after_dropna": 24, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 00:32:57.996595", "score": 1.0, "model": "o4-mini", "provider": "openai", "language": "pt", "prompt_type": "mcq"}
{"dataset": "x-fact-in-domain", "idx_after_dropna": 13, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 00:32:57.997638", "score": 1.0, "model": "o4-mini", "provider": "openai", "language": "pt", "prompt_type": "mcq"}
{"dataset": "x-fact-in-domain", "idx_after_dropna": 22, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 00:32:58.712150", "score": 1.0, "model": "o4-mini", "provider": "openai", "language": "ta", "prompt_type": "mcq"}
{"dataset": "x-fact-in-domain", "idx_after_dropna": 25, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 00:33:00.247181", "score": 1.0, "model": "o4-mini", "provider": "openai", "language": "de", "prompt_type": "mcq"}
{"dataset": "x-fact-in-domain", "idx_after_dropna": 29, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 00:33:01.102689", "score": 1.0, "model": "o4-mini", "provider": "openai", "language": "pt", "prompt_type": "mcq"}
{"dataset": "x-fact-in-domain", "idx_after_dropna": 30, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 00:33:01.803874", "score": 1.0, "model": "o4-mini", "provider": "openai", "language": "id", "prompt_type": "mcq"}
{"dataset": "x-fact-in-domain", "idx_after_dropna": 0, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 00:33:02.289738", "score": 0.5, "model": "o4-mini", "provider": "openai", "language": "pt", "prompt_type": "mcq"}
{"dataset": "x-fact-in-domain", "idx_after_dropna": 31, "raw_pred": "D", "pred": "complicated/hard to categorise", "ground_truth": "false", "time": "2025-05-18 00:33:02.340859", "score": 0.5, "model": "o4-mini", "provider": "openai", "language": "pt", "prompt_type": "mcq"}
{"dataset": "x-fact-in-domain", "idx_after_dropna": 27, "raw_pred": "D", "pred": "complicated/hard to categorise", "ground_truth": "false", "time": "2025-05-18 00:33:02.362260", "score": 0.5, "model": "o4-mini", "provider": "openai", "language": "sr", "prompt_type": "mcq"}
{"dataset": "x-fact-in-domain", "idx_after_dropna": 26, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 00:33:02.898811", "score": 1.0, "model": "o4-mini", "provider": "openai", "language": "ar", "prompt_type": "mcq"}
{"dataset": "x-fact-in-domain", "idx_after_dropna": 28, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 00:33:03.524062", "score": 0.25, "model": "o4-mini", "provider": "openai", "language": "ar", "prompt_type": "mcq"}
{"dataset": "x-fact-in-domain", "idx_after_dropna": 15, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "true", "time": "2025-05-18 00:33:05.965498", "score": 0.5, "model": "o4-mini", "provider": "openai", "language": "tr", "prompt_type": "mcq"}
{"dataset": "x-fact-in-domain", "idx_after_dropna": 35, "raw_pred": "D", "pred": "complicated/hard to categorise", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 00:33:06.595869", "score": 1.0, "model": "o4-mini", "provider": "openai", "language": "ro", "prompt_type": "mcq"}
{"dataset": "x-fact-in-domain", "idx_after_dropna": 36, "raw_pred": "A", "pred": "true", "ground_truth": "partly true/misleading", "time": "2025-05-18 00:33:08.175832", "score": 0.25, "model": "o4-mini", "provider": "openai", "language": "pt", "prompt_type": "mcq"}
{"dataset": "x-fact-in-domain", "idx_after_dropna": 32, "raw_pred": "A", "pred": "true", "ground_truth": "false", "time": "2025-05-18 00:33:09.055780", "score": 0.0, "model": "o4-mini", "provider": "openai", "language": "ro", "prompt_type": "mcq"}
{"dataset": "x-fact-in-domain", "idx_after_dropna": 39, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 00:33:09.569612", "score": 1.0, "model": "o4-mini", "provider": "openai", "language": "ar", "prompt_type": "mcq"}
{"dataset": "x-fact-in-domain", "idx_after_dropna": 37, "raw_pred": "G", "pred": "false", "ground_truth": "true", "time": "2025-05-18 00:33:10.796701", "score": 0.0, "model": "o4-mini", "provider": "openai", "language": "pl", "prompt_type": "mcq"}
{"dataset": "x-fact-in-domain", "idx_after_dropna": 23, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "partly true/misleading", "time": "2025-05-18 00:33:10.812202", "score": 1.0, "model": "o4-mini", "provider": "openai", "language": "ka", "prompt_type": "mcq"}
{"dataset": "x-fact-in-domain", "idx_after_dropna": 20, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "true", "time": "2025-05-18 00:33:11.718071", "score": 0.5, "model": "o4-mini", "provider": "openai", "language": "pt", "prompt_type": "mcq"}
{"dataset": "x-fact-in-domain", "idx_after_dropna": 40, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 00:33:12.636391", "score": 0.5, "model": "o4-mini", "provider": "openai", "language": "ar", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 0, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "true", "time": "2025-05-18 10:42:36.066195", "score": 0.5, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 4, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:42:36.067561", "score": 0.25, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "gu", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 2, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:42:36.101387", "score": 0.25, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "mr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 7, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:42:36.162644", "score": 1.0, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 9, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 10:42:36.164026", "score": 0.0, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 3, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:42:36.166092", "score": 1.0, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 1, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:42:36.170752", "score": 0.25, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 5, "raw_pred": "A", "pred": "true", "ground_truth": "mostly true", "time": "2025-05-18 10:42:36.224330", "score": 0.75, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 11, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 10:42:36.354463", "score": 0.5, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "nl", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 10, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:42:36.479072", "score": 1.0, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "si", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 16, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:42:36.479745", "score": 0.25, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 17, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 10:42:36.498891", "score": 0.5, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 14, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:42:36.505954", "score": 1.0, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 12, "raw_pred": "D", "pred": "complicated/hard to categorise", "ground_truth": "mostly false", "time": "2025-05-18 10:42:36.536797", "score": 0.5, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "az", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 13, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 10:42:36.541062", "score": 0.0, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 15, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:42:36.631717", "score": 0.25, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 21, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:42:36.751758", "score": 0.25, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 18, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:42:36.770606", "score": 0.25, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "mr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 19, "raw_pred": "D", "pred": "complicated/hard to categorise", "ground_truth": "false", "time": "2025-05-18 10:42:36.773716", "score": 0.5, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "az", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 22, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 10:42:36.777936", "score": 0.5, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "az", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 23, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 10:42:36.778886", "score": 0.75, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 20, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "mostly false", "time": "2025-05-18 10:42:36.844314", "score": 0.5, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 8, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:42:36.905627", "score": 0.25, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 25, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:42:36.911734", "score": 0.25, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "pa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 24, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 10:42:36.955660", "score": 0.75, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 26, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:42:36.963275", "score": 1.0, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 27, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:42:37.015340", "score": 1.0, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 30, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "true", "time": "2025-05-18 10:42:37.027031", "score": 0.5, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 29, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:42:37.079686", "score": 1.0, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 33, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 10:42:37.129595", "score": 0.0, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 31, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:42:37.130420", "score": 0.25, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 32, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:42:37.276257", "score": 1.0, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 35, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "mostly true", "time": "2025-05-18 10:42:37.276896", "score": 0.75, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 34, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 10:42:37.281882", "score": 0.75, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 36, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:42:37.290435", "score": 1.0, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 38, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:42:37.413643", "score": 1.0, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 28, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:42:37.601727", "score": 0.25, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 42, "raw_pred": "A", "pred": "true", "ground_truth": "mostly true", "time": "2025-05-18 10:42:37.606722", "score": 0.75, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 6, "raw_pred": "F", "pred": "mostly false", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 10:42:37.607628", "score": 0.0, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 39, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "mostly false", "time": "2025-05-18 10:42:38.274690", "score": 0.5, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 40, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 10:42:38.504051", "score": 0.5, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "nl", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 37, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:42:38.507640", "score": 1.0, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 45, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:42:38.694331", "score": 1.0, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 41, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:42:38.714149", "score": 1.0, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 52, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:42:39.123891", "score": 1.0, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "az", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 53, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 10:42:39.134259", "score": 0.75, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 47, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:42:39.250148", "score": 1.0, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 48, "raw_pred": "D", "pred": "complicated/hard to categorise", "ground_truth": "false", "time": "2025-05-18 10:42:39.256291", "score": 0.5, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 50, "raw_pred": "G", "pred": "false", "ground_truth": "true", "time": "2025-05-18 10:42:39.451697", "score": 0.0, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 51, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 10:42:39.452966", "score": 0.5, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "si", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 54, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:42:39.453547", "score": 1.0, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "az", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 55, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 10:42:39.453890", "score": 0.5, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 46, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 10:42:39.580381", "score": 0.5, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 49, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:42:39.626551", "score": 1.0, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 56, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 10:42:39.627102", "score": 0.75, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 57, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:42:39.653217", "score": 0.25, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "si", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 60, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 10:42:39.792017", "score": 0.5, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 61, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 10:42:39.817973", "score": 0.5, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 64, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 10:42:39.897490", "score": 0.5, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 58, "raw_pred": "A", "pred": "true", "ground_truth": "true", "time": "2025-05-18 10:42:39.901308", "score": 1.0, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 59, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 10:42:39.902016", "score": 0.75, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 63, "raw_pred": "G", "pred": "false", "ground_truth": "true", "time": "2025-05-18 10:42:39.913914", "score": 0.0, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 62, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:42:40.015618", "score": 1.0, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 65, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 10:42:40.017723", "score": 0.75, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 67, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 10:42:40.085075", "score": 0.5, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "mr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 71, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 10:42:40.213463", "score": 0.5, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 68, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:42:40.241023", "score": 0.25, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "pa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 43, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 10:42:40.342312", "score": 0.5, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 66, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:42:40.342991", "score": 1.0, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 74, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:42:40.358202", "score": 1.0, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 69, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 10:42:40.439551", "score": 0.75, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 75, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:42:40.441141", "score": 1.0, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "mr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 73, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:42:40.444643", "score": 0.25, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 78, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:42:40.643666", "score": 1.0, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 77, "raw_pred": "G", "pred": "false", "ground_truth": "true", "time": "2025-05-18 10:42:40.647793", "score": 0.0, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 79, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 10:42:40.648864", "score": 0.5, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 82, "raw_pred": "A", "pred": "true", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 10:42:40.697797", "score": 0.0, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 72, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 10:42:40.699178", "score": 0.5, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 70, "raw_pred": "G", "pred": "false", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 10:42:40.702123", "score": 0.0, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 44, "raw_pred": "D", "pred": "complicated/hard to categorise", "ground_truth": "true", "time": "2025-05-18 10:42:40.705538", "score": 0.0, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 81, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 10:42:40.789451", "score": 0.5, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 76, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:42:40.795543", "score": 1.0, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "si", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 84, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:42:40.940937", "score": 1.0, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 87, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 10:42:40.944557", "score": 0.75, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 80, "raw_pred": "G", "pred": "false", "ground_truth": "true", "time": "2025-05-18 10:42:41.024242", "score": 0.0, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 85, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:42:41.031361", "score": 0.25, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 88, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:42:41.035283", "score": 1.0, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 83, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:42:41.037495", "score": 1.0, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 89, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:42:41.050459", "score": 1.0, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 93, "raw_pred": "G", "pred": "false", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 10:42:41.251335", "score": 0.0, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 92, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:42:41.348448", "score": 1.0, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 94, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:42:41.349151", "score": 1.0, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 95, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 10:42:41.362433", "score": 0.0, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 96, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "mostly false", "time": "2025-05-18 10:42:41.376611", "score": 0.5, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 86, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:42:41.383728", "score": 1.0, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 91, "raw_pred": "G", "pred": "false", "ground_truth": "true", "time": "2025-05-18 10:42:41.384328", "score": 0.0, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 98, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:42:41.389113", "score": 1.0, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 99, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:42:41.597293", "score": 1.0, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "nl", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 106, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:42:41.681811", "score": 0.25, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 105, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 10:42:41.685604", "score": 0.5, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 101, "raw_pred": "G", "pred": "false", "ground_truth": "true", "time": "2025-05-18 10:42:41.687081", "score": 0.0, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 102, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 10:42:41.691120", "score": 0.5, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 103, "raw_pred": "A", "pred": "true", "ground_truth": "true", "time": "2025-05-18 10:42:41.729256", "score": 1.0, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "az", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 100, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 10:42:41.900509", "score": 0.5, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 104, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 10:42:41.901234", "score": 0.5, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "nl", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 110, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:42:41.946025", "score": 1.0, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "si", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 109, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:42:41.952108", "score": 1.0, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 111, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:42:42.057374", "score": 1.0, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "mr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 90, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "true", "time": "2025-05-18 10:42:42.087356", "score": 0.5, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 107, "raw_pred": "G", "pred": "false", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 10:42:42.090517", "score": 0.0, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 114, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:42:42.204891", "score": 0.25, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 97, "raw_pred": "A", "pred": "true", "ground_truth": "mostly false", "time": "2025-05-18 10:42:42.207324", "score": 0.25, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 112, "raw_pred": "G", "pred": "false", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 10:42:42.207750", "score": 0.0, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 115, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 10:42:42.213129", "score": 0.75, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 113, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:42:42.215942", "score": 1.0, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 124, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 10:42:42.726113", "score": 0.75, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 122, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 10:42:42.726706", "score": 0.5, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 121, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 10:42:42.727774", "score": 0.0, "model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "provider": "together", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 1, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:44:22.152512", "score": 0.25, "model": "gemini-2.0-flash", "provider": "gemini", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 2, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:44:22.155722", "score": 0.25, "model": "gemini-2.0-flash", "provider": "gemini", "language": "mr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 3, "raw_pred": "D", "pred": "complicated/hard to categorise", "ground_truth": "false", "time": "2025-05-18 10:44:22.171846", "score": 0.5, "model": "gemini-2.0-flash", "provider": "gemini", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 4, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:44:22.179574", "score": 0.25, "model": "gemini-2.0-flash", "provider": "gemini", "language": "gu", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 0, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "true", "time": "2025-05-18 10:44:22.208538", "score": 0.5, "model": "gemini-2.0-flash", "provider": "gemini", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 6, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 10:44:22.211963", "score": 0.0, "model": "gemini-2.0-flash", "provider": "gemini", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 5, "raw_pred": "A", "pred": "true", "ground_truth": "mostly true", "time": "2025-05-18 10:44:22.212067", "score": 0.75, "model": "gemini-2.0-flash", "provider": "gemini", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 8, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:44:22.232513", "score": 0.25, "model": "gemini-2.0-flash", "provider": "gemini", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 9, "raw_pred": "D", "pred": "complicated/hard to categorise", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 10:44:22.241075", "score": 1.0, "model": "gemini-2.0-flash", "provider": "gemini", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 7, "raw_pred": "D", "pred": "complicated/hard to categorise", "ground_truth": "false", "time": "2025-05-18 10:44:22.254662", "score": 0.5, "model": "gemini-2.0-flash", "provider": "gemini", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 10, "raw_pred": "D", "pred": "complicated/hard to categorise", "ground_truth": "false", "time": "2025-05-18 10:44:22.613570", "score": 0.5, "model": "gemini-2.0-flash", "provider": "gemini", "language": "si", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 11, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 10:44:22.639774", "score": 0.5, "model": "gemini-2.0-flash", "provider": "gemini", "language": "nl", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 12, "raw_pred": "D", "pred": "complicated/hard to categorise", "ground_truth": "mostly false", "time": "2025-05-18 10:44:22.907734", "score": 0.5, "model": "gemini-2.0-flash", "provider": "gemini", "language": "az", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 13, "raw_pred": "D", "pred": "complicated/hard to categorise", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 10:44:22.918591", "score": 1.0, "model": "gemini-2.0-flash", "provider": "gemini", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 14, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:44:23.041187", "score": 1.0, "model": "gemini-2.0-flash", "provider": "gemini", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 9, "raw_pred": "G", "pred": "false", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 10:59:21.654780", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 8, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:59:21.657079", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 1, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:59:21.666821", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 2, "raw_pred": "A", "pred": "true", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:59:21.668832", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "mr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 7, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:21.669554", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 3, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 10:59:21.675213", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 6, "raw_pred": "G", "pred": "false", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 10:59:21.675904", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 0, "raw_pred": "F", "pred": "mostly false", "ground_truth": "true", "time": "2025-05-18 10:59:21.682281", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 5, "raw_pred": "D", "pred": "complicated/hard to categorise", "ground_truth": "mostly true", "time": "2025-05-18 10:59:21.684630", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 4, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:59:21.687409", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "gu", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 10, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:22.162047", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "si", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 11, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 10:59:22.176209", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "nl", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 14, "raw_pred": "A", "pred": "true", "ground_truth": "false", "time": "2025-05-18 10:59:22.325485", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 13, "raw_pred": "G", "pred": "false", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 10:59:22.358435", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 12, "raw_pred": "D", "pred": "complicated/hard to categorise", "ground_truth": "mostly false", "time": "2025-05-18 10:59:22.360721", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "az", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 17, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:22.369323", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 18, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:59:22.374163", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "mr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 15, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:59:22.375661", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 19, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:22.382938", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "az", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 16, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:59:22.384047", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 20, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 10:59:22.398468", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 21, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:59:22.400096", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 22, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:22.489890", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "az", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 23, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:22.649784", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 24, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 10:59:22.734276", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 25, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:59:22.985957", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "pa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 26, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 10:59:23.066679", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 29, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:59:23.092876", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 28, "raw_pred": "D", "pred": "complicated/hard to categorise", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:59:23.094147", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 30, "raw_pred": "G", "pred": "false", "ground_truth": "true", "time": "2025-05-18 10:59:23.103147", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 32, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:23.105903", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 27, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:23.110252", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 34, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 10:59:23.111581", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 31, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:59:23.112912", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 33, "raw_pred": "A", "pred": "true", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 10:59:23.118049", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 35, "raw_pred": "D", "pred": "complicated/hard to categorise", "ground_truth": "mostly true", "time": "2025-05-18 10:59:23.164026", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 36, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:23.224950", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 37, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:23.332187", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 38, "raw_pred": "F", "pred": "mostly false", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:59:23.455714", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 39, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "mostly false", "time": "2025-05-18 10:59:23.700242", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 40, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 10:59:23.762750", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "nl", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 44, "raw_pred": "G", "pred": "false", "ground_truth": "true", "time": "2025-05-18 10:59:23.805913", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 43, "raw_pred": "D", "pred": "complicated/hard to categorise", "ground_truth": "false", "time": "2025-05-18 10:59:23.813706", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 41, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:23.816720", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 46, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 10:59:23.827771", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 48, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:23.829471", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 45, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 10:59:23.831972", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 42, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "mostly true", "time": "2025-05-18 10:59:23.836076", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 47, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:59:23.843547", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 49, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:23.858448", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 50, "raw_pred": "G", "pred": "false", "ground_truth": "true", "time": "2025-05-18 10:59:23.933961", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 51, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:23.972645", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "si", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 52, "raw_pred": "A", "pred": "true", "ground_truth": "false", "time": "2025-05-18 10:59:24.221429", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "az", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 53, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 10:59:24.258030", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 55, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 10:59:24.495698", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 54, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:24.501101", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "az", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 56, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 10:59:24.501503", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 59, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 10:59:24.507075", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 57, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:59:24.525385", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "si", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 58, "raw_pred": "A", "pred": "true", "ground_truth": "true", "time": "2025-05-18 10:59:24.527161", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 60, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 10:59:24.535212", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 61, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:24.537639", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 63, "raw_pred": "G", "pred": "false", "ground_truth": "true", "time": "2025-05-18 10:59:24.552211", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 62, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 10:59:24.559812", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 64, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:24.859787", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 66, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:24.993955", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 65, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 10:59:25.004719", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 67, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 10:59:25.088454", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "mr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 69, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 10:59:25.150153", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 70, "raw_pred": "F", "pred": "mostly false", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 10:59:25.164342", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 68, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:59:25.186887", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "pa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 71, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:25.210555", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 74, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:25.219033", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 75, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:59:25.228007", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "mr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 72, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:25.232514", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 73, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:59:25.235284", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 76, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:25.244453", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "si", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 77, "raw_pred": "G", "pred": "false", "ground_truth": "true", "time": "2025-05-18 10:59:25.245032", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 78, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:59:25.315830", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 79, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:25.341164", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 80, "raw_pred": "G", "pred": "false", "ground_truth": "true", "time": "2025-05-18 10:59:25.357228", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 82, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 10:59:25.381999", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 81, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:25.387289", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 83, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:25.421304", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 85, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:59:25.453529", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 87, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 10:59:25.454073", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 84, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 10:59:25.459322", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 86, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:59:25.468933", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 88, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:25.480284", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 89, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 10:59:25.495005", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 90, "raw_pred": "G", "pred": "false", "ground_truth": "true", "time": "2025-05-18 10:59:25.512323", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 92, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:25.540308", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 91, "raw_pred": "G", "pred": "false", "ground_truth": "true", "time": "2025-05-18 10:59:25.551304", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 93, "raw_pred": "G", "pred": "false", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 10:59:25.579381", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 94, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:59:25.673134", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 95, "raw_pred": "G", "pred": "false", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 10:59:25.705858", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 96, "raw_pred": "D", "pred": "complicated/hard to categorise", "ground_truth": "mostly false", "time": "2025-05-18 10:59:25.847871", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 98, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 10:59:26.009688", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 97, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 10:59:26.017622", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 99, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 10:59:26.072744", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "nl", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 100, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:26.109275", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 102, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:26.130962", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 101, "raw_pred": "G", "pred": "false", "ground_truth": "true", "time": "2025-05-18 10:59:26.133967", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 105, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:26.156603", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 104, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 10:59:26.156876", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "nl", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 103, "raw_pred": "G", "pred": "false", "ground_truth": "true", "time": "2025-05-18 10:59:26.164504", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "az", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 106, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:59:26.172030", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 107, "raw_pred": "G", "pred": "false", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 10:59:26.182121", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 108, "raw_pred": "F", "pred": "mostly false", "ground_truth": "true", "time": "2025-05-18 10:59:26.183361", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 109, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 10:59:26.244941", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 110, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:26.303353", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "si", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 111, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 10:59:26.312933", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "mr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 112, "raw_pred": "F", "pred": "mostly false", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 10:59:26.326035", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 114, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:59:26.360067", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 113, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:26.374489", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 116, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:26.395260", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 115, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 10:59:26.401919", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 117, "raw_pred": "G", "pred": "false", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 10:59:26.411663", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 119, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 10:59:26.413029", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 118, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:26.417117", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "gu", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 120, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 10:59:26.463285", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 121, "raw_pred": "A", "pred": "true", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 10:59:26.479416", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 122, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 10:59:26.498920", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 123, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:59:26.547524", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 124, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 10:59:26.571569", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 125, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:26.589228", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 126, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:26.595799", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "si", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 128, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:59:26.603104", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 129, "raw_pred": "F", "pred": "mostly false", "ground_truth": "mostly true", "time": "2025-05-18 10:59:26.607332", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 127, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:59:26.611814", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 130, "raw_pred": "A", "pred": "true", "ground_truth": "true", "time": "2025-05-18 10:59:26.628152", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 131, "raw_pred": "F", "pred": "mostly false", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:59:26.646820", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "nl", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 132, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:26.671896", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "nl", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 133, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:59:26.709874", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 134, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 10:59:26.744959", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 135, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:59:26.773502", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "pa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 136, "raw_pred": "D", "pred": "complicated/hard to categorise", "ground_truth": "false", "time": "2025-05-18 10:59:26.784704", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 137, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:59:26.793611", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "gu", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 140, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:26.814445", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 139, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 10:59:26.817680", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 138, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:26.823377", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "pa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 141, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 10:59:26.830696", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 142, "raw_pred": "D", "pred": "complicated/hard to categorise", "ground_truth": "mostly true", "time": "2025-05-18 10:59:26.844730", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 143, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 10:59:26.875649", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 144, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:26.915542", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 145, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:59:26.932978", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 146, "raw_pred": "G", "pred": "false", "ground_truth": "true", "time": "2025-05-18 10:59:26.939390", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 148, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:59:26.980931", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 149, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 10:59:26.990801", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 152, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:59:27.012913", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 150, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 10:59:27.020618", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 153, "raw_pred": "G", "pred": "false", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 10:59:27.047042", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 147, "raw_pred": "G", "pred": "false", "ground_truth": "true", "time": "2025-05-18 10:59:27.053709", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 151, "raw_pred": "G", "pred": "false", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 10:59:27.055931", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "nl", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 154, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:27.091366", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "pa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 155, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 10:59:27.110269", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 156, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:27.120638", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 158, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 10:59:27.175131", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 159, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:59:27.182051", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "pa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 157, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:27.184108", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "pa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 160, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:59:27.198182", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 161, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 10:59:27.220337", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 163, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:27.232661", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 164, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 10:59:27.255180", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "az", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 165, "raw_pred": "G", "pred": "false", "ground_truth": "true", "time": "2025-05-18 10:59:27.278148", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 166, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:27.313058", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "pa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 168, "raw_pred": "D", "pred": "complicated/hard to categorise", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:59:27.353335", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 169, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:27.363380", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 167, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:27.372577", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 170, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 10:59:27.375654", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 171, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:59:27.385723", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 173, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:27.414414", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 172, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:59:27.424253", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "mr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 174, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:59:27.429121", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "si", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 175, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 10:59:27.464058", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 176, "raw_pred": "D", "pred": "complicated/hard to categorise", "ground_truth": "true", "time": "2025-05-18 10:59:27.482404", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "nl", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 178, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 10:59:27.524438", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 177, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:59:27.535373", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 180, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:27.556615", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 181, "raw_pred": "F", "pred": "mostly false", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 10:59:27.557272", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 179, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:59:27.563332", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "pa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 183, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 10:59:27.585633", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 182, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:27.590358", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 184, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:27.600899", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 185, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:27.631651", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 186, "raw_pred": "G", "pred": "false", "ground_truth": "other", "time": "2025-05-18 10:59:27.660339", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 187, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 10:59:27.690727", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 188, "raw_pred": "B", "pred": "mostly true", "ground_truth": "false", "time": "2025-05-18 10:59:27.713555", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 189, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:27.746557", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 190, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:59:27.749042", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 191, "raw_pred": "A", "pred": "true", "ground_truth": "false", "time": "2025-05-18 10:59:27.755686", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 192, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 10:59:27.759661", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 193, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 10:59:27.766539", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 194, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 10:59:27.775492", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 195, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "mostly true", "time": "2025-05-18 10:59:27.811597", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 196, "raw_pred": "G", "pred": "false", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 10:59:27.828887", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 197, "raw_pred": "G", "pred": "false", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 10:59:27.858736", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 198, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:27.886716", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 199, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 10:59:27.972009", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 200, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:59:28.032844", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "gu", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 201, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:28.220282", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 202, "raw_pred": "F", "pred": "mostly false", "ground_truth": "true", "time": "2025-05-18 10:59:28.314267", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 203, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:28.399483", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 204, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:28.401277", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "mr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 206, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:28.456617", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "az", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 205, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:28.471356", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "mr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 210, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 10:59:28.480099", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 207, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:28.487546", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 208, "raw_pred": "G", "pred": "false", "ground_truth": "true", "time": "2025-05-18 10:59:28.488455", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 212, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:28.494173", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 209, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:28.500409", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 211, "raw_pred": "D", "pred": "complicated/hard to categorise", "ground_truth": "mostly false", "time": "2025-05-18 10:59:28.504422", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "az", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 214, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "mostly false", "time": "2025-05-18 10:59:28.571333", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 213, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 10:59:28.591664", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 215, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:59:28.639125", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 216, "raw_pred": "G", "pred": "false", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 10:59:28.665024", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 217, "raw_pred": "A", "pred": "true", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 10:59:28.692883", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 218, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:28.866945", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "pa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 219, "raw_pred": "F", "pred": "mostly false", "ground_truth": "mostly true", "time": "2025-05-18 10:59:28.887541", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 221, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:59:29.005720", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 220, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:59:29.011353", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 222, "raw_pred": "G", "pred": "false", "ground_truth": "true", "time": "2025-05-18 10:59:29.045897", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 224, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:59:29.141996", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "si", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 223, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:29.151336", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 225, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:59:29.192123", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 226, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:29.203152", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "nl", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 227, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:59:29.217230", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 228, "raw_pred": "F", "pred": "mostly false", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 10:59:29.278965", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 229, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:29.299325", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "mr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 232, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 10:59:29.306221", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 230, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 10:59:29.311903", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 233, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:29.317096", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 231, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:29.328157", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "az", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 234, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:59:29.338067", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 235, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:59:29.361361", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 237, "raw_pred": "A", "pred": "true", "ground_truth": "false", "time": "2025-05-18 10:59:29.379963", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 236, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:29.389191", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "si", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 238, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:59:29.441463", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "nl", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 239, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:29.474439", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 240, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:59:29.502593", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "gu", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 242, "raw_pred": "F", "pred": "mostly false", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:59:29.507400", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 245, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:59:29.533950", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 241, "raw_pred": "G", "pred": "false", "ground_truth": "true", "time": "2025-05-18 10:59:29.539137", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 243, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 10:59:29.542722", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 244, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:59:29.549157", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 246, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:29.551646", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 247, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:59:29.579873", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 248, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:29.629485", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "si", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 249, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "mostly false", "time": "2025-05-18 10:59:29.635376", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 250, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:29.678607", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 251, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 10:59:29.697592", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 252, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 10:59:29.737811", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 253, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 10:59:29.771321", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 254, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 10:59:29.771642", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "gu", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 256, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "mostly false", "time": "2025-05-18 10:59:29.785716", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 255, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:59:29.790891", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "gu", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 257, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:29.799758", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 259, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:59:29.811566", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "pa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 258, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 10:59:29.814946", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 260, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:29.854017", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 261, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 10:59:29.878739", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 262, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 10:59:29.910835", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 263, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:29.957753", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "gu", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 264, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 10:59:29.958449", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 5, "raw_pred": "G", "pred": "false", "ground_truth": "mostly true", "time": "2025-05-18 10:59:41.112797", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 6, "raw_pred": "G", "pred": "false", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 10:59:41.118739", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 4, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:59:41.121658", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "gu", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 8, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:59:41.122502", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 3, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 10:59:41.124085", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 2, "raw_pred": "A", "pred": "true", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:59:41.123310", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "mr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 1, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:59:41.124975", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 0, "raw_pred": "G", "pred": "false", "ground_truth": "true", "time": "2025-05-18 10:59:41.129370", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 9, "raw_pred": "G", "pred": "false", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 10:59:41.131442", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 7, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:41.132162", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 10, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:41.691703", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "si", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 11, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 10:59:41.787154", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "nl", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 17, "raw_pred": "D", "pred": "complicated/hard to categorise", "ground_truth": "false", "time": "2025-05-18 10:59:41.836536", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 16, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:59:41.843071", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 15, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:59:41.852148", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 14, "raw_pred": "A", "pred": "true", "ground_truth": "false", "time": "2025-05-18 10:59:41.852875", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 19, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:41.854836", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "az", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 13, "raw_pred": "G", "pred": "false", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 10:59:41.860741", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 20, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 10:59:41.871775", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 12, "raw_pred": "D", "pred": "complicated/hard to categorise", "ground_truth": "mostly false", "time": "2025-05-18 10:59:41.872632", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "az", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 18, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:59:41.872996", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "mr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 21, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:59:41.965553", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 22, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:42.047694", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "az", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 23, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:42.251601", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 24, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 10:59:42.422745", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 26, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 10:59:42.452751", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 25, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:59:42.466061", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "pa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 28, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:59:42.502662", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 27, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:42.508610", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 32, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:42.523906", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 29, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:59:42.525645", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 30, "raw_pred": "G", "pred": "false", "ground_truth": "true", "time": "2025-05-18 10:59:42.528084", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 31, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:59:42.528673", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 33, "raw_pred": "A", "pred": "true", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 10:59:42.528386", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 34, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 10:59:42.600612", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 35, "raw_pred": "G", "pred": "false", "ground_truth": "mostly true", "time": "2025-05-18 10:59:42.618484", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 36, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:42.629477", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 37, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:42.671779", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 38, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:59:42.678894", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 39, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "mostly false", "time": "2025-05-18 10:59:42.845851", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 40, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 10:59:42.906952", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "nl", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 43, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:43.003303", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 42, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "mostly true", "time": "2025-05-18 10:59:43.005586", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 41, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:43.030388", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 44, "raw_pred": "G", "pred": "false", "ground_truth": "true", "time": "2025-05-18 10:59:43.163104", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 45, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:43.249276", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 46, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 10:59:43.255331", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 48, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:43.271431", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 47, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:59:43.276771", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 49, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:43.311274", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 50, "raw_pred": "G", "pred": "false", "ground_truth": "true", "time": "2025-05-18 10:59:43.351780", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 51, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:43.367591", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "si", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 54, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:43.369648", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "az", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 53, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 10:59:43.376439", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 52, "raw_pred": "A", "pred": "true", "ground_truth": "false", "time": "2025-05-18 10:59:43.385810", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "az", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 55, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 10:59:43.410381", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 56, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 10:59:43.432424", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 57, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:59:43.440338", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "si", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 58, "raw_pred": "A", "pred": "true", "ground_truth": "true", "time": "2025-05-18 10:59:43.452573", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 59, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 10:59:43.481360", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 60, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 10:59:43.526702", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 61, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:43.540695", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 63, "raw_pred": "G", "pred": "false", "ground_truth": "true", "time": "2025-05-18 10:59:43.549388", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 62, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 10:59:43.550342", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 65, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 10:59:43.578146", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 64, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:43.578633", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 66, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:43.598668", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 67, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 10:59:43.610164", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "mr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 68, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:59:43.626250", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "pa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 69, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 10:59:43.639774", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 70, "raw_pred": "F", "pred": "mostly false", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 10:59:43.698889", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 71, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:43.701797", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 72, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:43.730987", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 73, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:59:43.737762", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 74, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:43.746834", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 75, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:59:43.755589", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "mr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 76, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:43.768172", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "si", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 77, "raw_pred": "G", "pred": "false", "ground_truth": "true", "time": "2025-05-18 10:59:43.784121", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 79, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:43.797465", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 78, "raw_pred": "F", "pred": "mostly false", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:59:43.800821", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 81, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:43.865129", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 80, "raw_pred": "G", "pred": "false", "ground_truth": "true", "time": "2025-05-18 10:59:43.865928", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 83, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:43.899149", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 82, "raw_pred": "D", "pred": "complicated/hard to categorise", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 10:59:43.903728", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 85, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:59:43.918244", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 84, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:43.922547", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 86, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:59:43.937705", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 87, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 10:59:43.944244", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 88, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:43.956624", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 89, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 10:59:43.970501", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 91, "raw_pred": "G", "pred": "false", "ground_truth": "true", "time": "2025-05-18 10:59:44.041315", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 90, "raw_pred": "G", "pred": "false", "ground_truth": "true", "time": "2025-05-18 10:59:44.049955", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 93, "raw_pred": "G", "pred": "false", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 10:59:44.070224", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 92, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 10:59:44.076116", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 95, "raw_pred": "G", "pred": "false", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 10:59:44.084894", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 94, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:59:44.092269", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 97, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 10:59:44.111888", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 96, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 10:59:44.113074", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 98, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 10:59:44.130268", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 99, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 10:59:44.132244", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "nl", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 101, "raw_pred": "G", "pred": "false", "ground_truth": "true", "time": "2025-05-18 10:59:44.213493", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 100, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:44.222624", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 102, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:44.237553", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 105, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 10:59:44.252766", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 103, "raw_pred": "G", "pred": "false", "ground_truth": "true", "time": "2025-05-18 10:59:44.253053", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "az", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 104, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 10:59:44.256113", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "nl", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 106, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:59:44.274371", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 107, "raw_pred": "G", "pred": "false", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 10:59:44.288172", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 108, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "true", "time": "2025-05-18 10:59:44.290352", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 109, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 10:59:44.301224", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 110, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:44.377626", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "si", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 112, "raw_pred": "G", "pred": "false", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 10:59:44.392263", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 111, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 10:59:44.396474", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "mr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 115, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 10:59:44.451190", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 113, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:44.456271", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 114, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:59:44.457586", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 116, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:44.490507", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 119, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 10:59:44.491108", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 117, "raw_pred": "G", "pred": "false", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 10:59:44.490821", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 118, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:44.495934", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "gu", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 121, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 10:59:44.547677", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 120, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 10:59:44.554736", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 122, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 10:59:44.562911", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 124, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 10:59:44.711261", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 123, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:59:44.714174", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 125, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:44.725128", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 128, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:59:44.725885", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 127, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:59:44.737015", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 126, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:44.743761", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "si", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 129, "raw_pred": "G", "pred": "false", "ground_truth": "mostly true", "time": "2025-05-18 10:59:44.751916", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 130, "raw_pred": "D", "pred": "complicated/hard to categorise", "ground_truth": "true", "time": "2025-05-18 10:59:44.770565", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 132, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:44.783398", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "nl", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 131, "raw_pred": "F", "pred": "mostly false", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:59:44.784538", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "nl", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 133, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:59:44.906690", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 134, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:44.914065", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 136, "raw_pred": "D", "pred": "complicated/hard to categorise", "ground_truth": "false", "time": "2025-05-18 10:59:45.201895", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 135, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:59:45.215255", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "pa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 137, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:59:45.343586", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "gu", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 138, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:45.387637", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "pa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 140, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:45.399799", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 139, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 10:59:45.414604", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 143, "raw_pred": "D", "pred": "complicated/hard to categorise", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 10:59:45.429810", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 141, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 10:59:45.433873", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 142, "raw_pred": "D", "pred": "complicated/hard to categorise", "ground_truth": "mostly true", "time": "2025-05-18 10:59:45.437484", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 146, "raw_pred": "G", "pred": "false", "ground_truth": "true", "time": "2025-05-18 10:59:45.446722", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 145, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:59:45.453230", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 144, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:45.461361", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 147, "raw_pred": "G", "pred": "false", "ground_truth": "true", "time": "2025-05-18 10:59:45.497501", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 148, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:59:45.546583", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 150, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 10:59:45.587949", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 149, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 10:59:45.594921", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 151, "raw_pred": "G", "pred": "false", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 10:59:45.613669", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "nl", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 152, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:59:45.674884", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 153, "raw_pred": "G", "pred": "false", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 10:59:45.693324", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 155, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:45.703593", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 156, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:45.708625", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 154, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:45.712672", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "pa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 158, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 10:59:45.731929", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 157, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:45.734831", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "pa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 159, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:59:45.778831", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "pa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 160, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:59:45.779656", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 161, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 10:59:45.852116", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 163, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:45.879241", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 164, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 10:59:45.902971", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "az", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 165, "raw_pred": "G", "pred": "false", "ground_truth": "true", "time": "2025-05-18 10:59:45.911061", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 166, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:45.916689", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "pa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 168, "raw_pred": "D", "pred": "complicated/hard to categorise", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:59:45.918613", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 167, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 10:59:45.926527", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 169, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:45.962063", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 170, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 10:59:45.967019", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 173, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:46.059630", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 171, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:59:46.060371", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 172, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:59:46.063291", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "mr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 174, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:59:46.112094", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "si", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 177, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:59:46.136036", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 176, "raw_pred": "D", "pred": "complicated/hard to categorise", "ground_truth": "true", "time": "2025-05-18 10:59:46.158528", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "nl", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 180, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:46.164512", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 175, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 10:59:46.166213", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 178, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 10:59:46.173414", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 179, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 10:59:46.187422", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "pa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 181, "raw_pred": "F", "pred": "mostly false", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 10:59:46.287513", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 182, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 10:59:46.313026", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 183, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 10:59:46.316154", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 1, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:00:38.300511", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 8, "raw_pred": "F", "pred": "mostly false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:00:38.304593", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 0, "raw_pred": "G", "pred": "false", "ground_truth": "true", "time": "2025-05-18 11:00:38.308264", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 4, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:00:38.309967", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "gu", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 6, "raw_pred": "G", "pred": "false", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 11:00:38.313339", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 7, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:38.316098", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 5, "raw_pred": "G", "pred": "false", "ground_truth": "mostly true", "time": "2025-05-18 11:00:38.319258", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 9, "raw_pred": "G", "pred": "false", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 11:00:38.321746", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 2, "raw_pred": "A", "pred": "true", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:00:38.326159", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "mr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 3, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:38.328687", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 11, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 11:00:38.887914", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "nl", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 10, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:38.904860", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "si", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 14, "raw_pred": "A", "pred": "true", "ground_truth": "false", "time": "2025-05-18 11:00:38.956104", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 12, "raw_pred": "D", "pred": "complicated/hard to categorise", "ground_truth": "mostly false", "time": "2025-05-18 11:00:38.958683", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "az", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 16, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:00:38.970857", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 13, "raw_pred": "G", "pred": "false", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 11:00:38.976407", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 19, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:38.977412", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "az", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 17, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:38.977095", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 15, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:00:38.983592", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 18, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:00:38.985573", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "mr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 20, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 11:00:39.050833", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 21, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:00:39.061077", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 22, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:39.139066", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "az", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 23, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:39.189055", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 24, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 11:00:39.519526", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 25, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:00:39.630947", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "pa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 26, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 11:00:39.645585", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 29, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:00:39.646160", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 30, "raw_pred": "G", "pred": "false", "ground_truth": "true", "time": "2025-05-18 11:00:39.658507", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 27, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:39.662804", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 28, "raw_pred": "D", "pred": "complicated/hard to categorise", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:00:39.666735", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 32, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:39.669444", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 33, "raw_pred": "A", "pred": "true", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 11:00:39.672573", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 31, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:00:39.676201", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 34, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 11:00:39.688872", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 35, "raw_pred": "D", "pred": "complicated/hard to categorise", "ground_truth": "mostly true", "time": "2025-05-18 11:00:39.808521", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 37, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:39.928605", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 36, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:39.941627", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 38, "raw_pred": "F", "pred": "mostly false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:00:40.260193", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 39, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 11:00:40.302248", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 40, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 11:00:40.346351", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "nl", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 43, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:40.354184", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 41, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:40.361586", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 45, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:40.362072", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 42, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "mostly true", "time": "2025-05-18 11:00:40.362825", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 44, "raw_pred": "F", "pred": "mostly false", "ground_truth": "true", "time": "2025-05-18 11:00:40.369341", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 47, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:00:40.379262", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 46, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:40.381945", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 48, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:40.426196", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 49, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:40.480187", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 50, "raw_pred": "G", "pred": "false", "ground_truth": "true", "time": "2025-05-18 11:00:40.521777", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 51, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:40.647727", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "si", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 53, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 11:00:41.000451", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 52, "raw_pred": "A", "pred": "true", "ground_truth": "false", "time": "2025-05-18 11:00:41.004931", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "az", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 54, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:41.007633", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "az", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 55, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 11:00:41.052648", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 57, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:00:41.056831", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "si", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 56, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 11:00:41.059614", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 60, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 11:00:41.067890", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 61, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:41.072747", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 59, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 11:00:41.075478", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 58, "raw_pred": "A", "pred": "true", "ground_truth": "true", "time": "2025-05-18 11:00:41.077110", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 64, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:41.181002", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 63, "raw_pred": "G", "pred": "false", "ground_truth": "true", "time": "2025-05-18 11:00:41.184903", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 62, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 11:00:41.188901", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 65, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 11:00:41.278673", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 66, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:41.428637", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 67, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 11:00:41.499266", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "mr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 68, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:00:41.632727", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "pa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 69, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 11:00:41.653446", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 71, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:41.704572", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 70, "raw_pred": "F", "pred": "mostly false", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 11:00:41.737602", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 74, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 11:00:41.766119", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 73, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:00:41.769562", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 72, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:41.787315", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 76, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:41.787823", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "si", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 75, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:00:41.791967", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "mr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 77, "raw_pred": "G", "pred": "false", "ground_truth": "true", "time": "2025-05-18 11:00:41.793183", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 78, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:00:41.819194", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 79, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 11:00:41.819585", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 80, "raw_pred": "G", "pred": "false", "ground_truth": "true", "time": "2025-05-18 11:00:41.873707", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 81, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:41.912523", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 83, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:41.929695", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 82, "raw_pred": "D", "pred": "complicated/hard to categorise", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 11:00:41.946930", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 85, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:00:42.151727", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 84, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:42.155548", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 86, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:00:42.218932", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 87, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 11:00:42.235749", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 89, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:42.324714", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 90, "raw_pred": "G", "pred": "false", "ground_truth": "true", "time": "2025-05-18 11:00:42.386056", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 88, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 11:00:42.389885", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 91, "raw_pred": "G", "pred": "false", "ground_truth": "true", "time": "2025-05-18 11:00:42.451251", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 92, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:42.472087", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 93, "raw_pred": "G", "pred": "false", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 11:00:42.505346", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 95, "raw_pred": "G", "pred": "false", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 11:00:42.597211", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 94, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:00:42.600103", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 97, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 11:00:42.715584", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 96, "raw_pred": "D", "pred": "complicated/hard to categorise", "ground_truth": "mostly false", "time": "2025-05-18 11:00:42.727849", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 98, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 11:00:42.783704", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 99, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 11:00:42.927464", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "nl", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 100, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:42.970444", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 102, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 11:00:43.011756", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 101, "raw_pred": "G", "pred": "false", "ground_truth": "true", "time": "2025-05-18 11:00:43.025050", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 103, "raw_pred": "G", "pred": "false", "ground_truth": "true", "time": "2025-05-18 11:00:43.074990", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "az", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 104, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 11:00:43.118014", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "nl", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 105, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 11:00:43.130996", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 106, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:00:43.137858", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 108, "raw_pred": "F", "pred": "mostly false", "ground_truth": "true", "time": "2025-05-18 11:00:43.155450", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 109, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 11:00:43.166981", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 107, "raw_pred": "G", "pred": "false", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 11:00:43.173787", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 110, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:43.179980", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "si", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 112, "raw_pred": "G", "pred": "false", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 11:00:43.183318", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 111, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 11:00:43.195045", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "mr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 113, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:43.237123", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 114, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:00:43.286381", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 115, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 11:00:43.290563", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 116, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:43.310120", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 117, "raw_pred": "G", "pred": "false", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 11:00:43.319849", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 118, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:43.329436", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "gu", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 119, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 11:00:43.343353", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 120, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 11:00:43.349063", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 122, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 11:00:43.367065", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 121, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 11:00:43.369519", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 123, "raw_pred": "F", "pred": "mostly false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:00:43.408355", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 125, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:43.449341", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 124, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 11:00:43.458278", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 126, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:43.468252", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "si", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 127, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:00:43.487340", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 129, "raw_pred": "F", "pred": "mostly false", "ground_truth": "mostly true", "time": "2025-05-18 11:00:43.502177", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 128, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:00:43.506310", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 130, "raw_pred": "D", "pred": "complicated/hard to categorise", "ground_truth": "true", "time": "2025-05-18 11:00:43.516564", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 132, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:43.528639", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "nl", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 131, "raw_pred": "F", "pred": "mostly false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:00:43.543382", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "nl", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 133, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:00:43.581836", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 135, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:00:43.616397", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "pa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 134, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 11:00:43.625654", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 136, "raw_pred": "D", "pred": "complicated/hard to categorise", "ground_truth": "false", "time": "2025-05-18 11:00:43.638464", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 137, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:00:43.647837", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "gu", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 140, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:43.673012", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 139, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 11:00:43.676797", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 138, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:43.678158", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "pa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 141, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 11:00:43.687504", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 142, "raw_pred": "D", "pred": "complicated/hard to categorise", "ground_truth": "mostly true", "time": "2025-05-18 11:00:43.702172", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 143, "raw_pred": "F", "pred": "mostly false", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 11:00:43.748405", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 144, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:43.779713", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 146, "raw_pred": "G", "pred": "false", "ground_truth": "true", "time": "2025-05-18 11:00:43.791181", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 145, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:00:43.794663", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 147, "raw_pred": "G", "pred": "false", "ground_truth": "true", "time": "2025-05-18 11:00:43.813233", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 148, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:00:43.865063", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 150, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 11:00:43.866657", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 149, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 11:00:43.871772", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 151, "raw_pred": "G", "pred": "false", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 11:00:43.884981", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "nl", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 152, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:00:43.897507", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 153, "raw_pred": "G", "pred": "false", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 11:00:43.917921", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 154, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:43.948844", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "pa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 155, "raw_pred": "A", "pred": "true", "ground_truth": "false", "time": "2025-05-18 11:00:43.962816", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 156, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:43.968670", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 157, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:43.969627", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "pa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 158, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 11:00:44.043023", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 159, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:00:44.053038", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "pa", "prompt_type": "mcq"}
{"score": 0}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 160, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:00:44.067286", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 161, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:44.067744", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 163, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:44.084334", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 164, "raw_pred": "D", "pred": "complicated/hard to categorise", "ground_truth": "mostly false", "time": "2025-05-18 11:00:44.119295", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "az", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 165, "raw_pred": "G", "pred": "false", "ground_truth": "true", "time": "2025-05-18 11:00:44.130897", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 167, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:44.150745", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 166, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:44.153900", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "pa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 168, "raw_pred": "D", "pred": "complicated/hard to categorise", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:00:44.202268", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 169, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:44.210141", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 170, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 11:00:44.240415", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 171, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:00:44.241114", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 172, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:00:44.255038", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "mr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 173, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:44.256779", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 174, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:00:44.275555", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "si", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 175, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 11:00:44.280780", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 176, "raw_pred": "D", "pred": "complicated/hard to categorise", "ground_truth": "true", "time": "2025-05-18 11:00:44.336397", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "nl", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 177, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:00:44.341178", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 178, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 11:00:44.373583", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 179, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:00:44.379157", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "pa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 183, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 11:00:44.413322", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 181, "raw_pred": "G", "pred": "false", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 11:00:44.422145", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 180, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:44.423051", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 182, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:44.427484", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 184, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 11:00:44.431492", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 185, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:44.450169", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 187, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:44.497417", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 186, "raw_pred": "G", "pred": "false", "ground_truth": "other", "time": "2025-05-18 11:00:44.504462", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 189, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:44.534650", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 188, "raw_pred": "A", "pred": "true", "ground_truth": "false", "time": "2025-05-18 11:00:44.543398", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 190, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:00:44.590688", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 192, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 11:00:44.651488", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 191, "raw_pred": "A", "pred": "true", "ground_truth": "false", "time": "2025-05-18 11:00:44.661021", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 193, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:44.683858", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 195, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "mostly true", "time": "2025-05-18 11:00:44.687112", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 194, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 11:00:44.689460", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 197, "raw_pred": "G", "pred": "false", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 11:00:44.713233", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 196, "raw_pred": "G", "pred": "false", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 11:00:44.716493", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 198, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:44.722446", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 199, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 11:00:44.728202", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 200, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:00:44.762619", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "gu", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 201, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 11:00:44.834887", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 202, "raw_pred": "F", "pred": "mostly false", "ground_truth": "true", "time": "2025-05-18 11:00:44.854995", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 203, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:44.865911", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 204, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:44.896623", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "mr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 205, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:44.910863", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "mr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 207, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:44.942845", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 206, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:44.948898", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "az", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 210, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 11:00:44.951253", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 209, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:44.951731", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 208, "raw_pred": "G", "pred": "false", "ground_truth": "true", "time": "2025-05-18 11:00:44.955702", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 211, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "mostly false", "time": "2025-05-18 11:00:45.013998", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "az", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 212, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:45.038794", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 213, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 11:00:45.039467", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 214, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "mostly false", "time": "2025-05-18 11:00:45.065600", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 215, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:00:45.085494", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 216, "raw_pred": "G", "pred": "false", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 11:00:45.147476", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 217, "raw_pred": "G", "pred": "false", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 11:00:45.251657", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 220, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:00:45.268323", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 218, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:45.269256", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "pa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 219, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "mostly true", "time": "2025-05-18 11:00:45.276394", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 223, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:45.277291", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 224, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:00:45.279624", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "si", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 221, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:00:45.282860", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 222, "raw_pred": "G", "pred": "false", "ground_truth": "true", "time": "2025-05-18 11:00:45.284594", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 225, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:00:45.290871", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 226, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:45.336892", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "nl", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 227, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:00:45.432666", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 228, "raw_pred": "G", "pred": "false", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 11:00:45.756646", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 229, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 11:00:45.789361", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "mr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 230, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:45.931341", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 235, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:00:46.000269", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 232, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 11:00:46.022156", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 238, "raw_pred": "A", "pred": "true", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:00:46.032154", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "nl", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 233, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:46.039879", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 231, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:46.038566", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "az", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 239, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:46.040346", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 236, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:46.039390", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "si", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 234, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:00:46.040714", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 237, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:46.043677", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 240, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:00:46.128080", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "gu", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 241, "raw_pred": "F", "pred": "mostly false", "ground_truth": "true", "time": "2025-05-18 11:00:46.202356", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 242, "raw_pred": "F", "pred": "mostly false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:00:46.228540", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 243, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 11:00:46.409325", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 246, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:46.727322", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 248, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:46.738402", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "si", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 249, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 11:00:46.739105", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 244, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:00:46.743277", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 247, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:00:46.743985", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 245, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:00:46.745227", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 250, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:46.755722", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 252, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 11:00:46.756522", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 251, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 11:00:46.766574", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 253, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 11:00:46.775213", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 254, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 11:00:47.072020", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "gu", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 256, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 11:00:47.330842", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 255, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:00:47.417846", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "gu", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 257, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:47.459480", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 261, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 11:00:47.476621", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 259, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:00:47.488521", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "pa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 263, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:47.496609", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "gu", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 264, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 11:00:47.498541", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 258, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 11:00:47.499326", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 262, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 11:00:47.504026", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 265, "raw_pred": "D", "pred": "complicated/hard to categorise", "ground_truth": "false", "time": "2025-05-18 11:00:47.507908", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 260, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:47.508580", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 266, "raw_pred": "A", "pred": "true", "ground_truth": "false", "time": "2025-05-18 11:00:47.584402", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 267, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:00:47.635632", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "mr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 268, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 11:00:47.644044", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 269, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:47.669858", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 270, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:48.065314", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 275, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:00:48.069086", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "az", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 271, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 11:00:48.091248", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 272, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:48.093823", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 273, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:00:48.113894", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 274, "raw_pred": "D", "pred": "complicated/hard to categorise", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:00:48.125208", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "nl", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 277, "raw_pred": "G", "pred": "false", "ground_truth": "other", "time": "2025-05-18 11:00:48.130982", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 276, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:48.134751", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "az", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 279, "raw_pred": "D", "pred": "complicated/hard to categorise", "ground_truth": "mostly false", "time": "2025-05-18 11:00:48.147253", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "az", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 278, "raw_pred": "G", "pred": "false", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 11:00:48.148781", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 281, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:48.236891", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 280, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 11:00:48.237272", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 283, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 11:00:48.258972", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 282, "raw_pred": "A", "pred": "true", "ground_truth": "false", "time": "2025-05-18 11:00:48.270866", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 284, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 11:00:48.277198", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 285, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 11:00:48.298077", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 286, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:48.305121", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 287, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:00:48.323985", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 288, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 11:00:48.345598", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 289, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:48.352564", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 290, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "mostly true", "time": "2025-05-18 11:00:48.404844", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 291, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:48.416687", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 293, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:00:48.428287", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 292, "raw_pred": "G", "pred": "false", "ground_truth": "mostly true", "time": "2025-05-18 11:00:48.436137", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 294, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:48.452385", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 295, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:48.458483", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 296, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 11:00:48.474296", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 297, "raw_pred": "F", "pred": "mostly false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:00:48.489355", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 298, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:48.517058", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 299, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:00:48.517324", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 300, "raw_pred": "F", "pred": "mostly false", "ground_truth": "mostly true", "time": "2025-05-18 11:00:48.559446", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 301, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "mostly false", "time": "2025-05-18 11:00:48.590422", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "az", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 302, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 11:00:48.598461", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 303, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:00:48.603248", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 305, "raw_pred": "A", "pred": "true", "ground_truth": "false", "time": "2025-05-18 11:00:48.630229", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 304, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:00:48.637461", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "mr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 306, "raw_pred": "A", "pred": "true", "ground_truth": "mostly false", "time": "2025-05-18 11:00:48.649320", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "az", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 307, "raw_pred": "A", "pred": "true", "ground_truth": "false", "time": "2025-05-18 11:00:48.660978", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 309, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 11:00:48.678731", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 308, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:48.693504", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 310, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 11:00:48.732789", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 311, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 11:00:48.752496", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "nl", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 313, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 11:00:48.784746", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 312, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:48.785550", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 314, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:48.805088", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "az", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 315, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:48.811968", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "si", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 316, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:00:48.829191", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 317, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 11:00:48.829754", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 318, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:00:48.847755", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 319, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "true", "time": "2025-05-18 11:00:48.873226", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 320, "raw_pred": "G", "pred": "false", "ground_truth": "mostly true", "time": "2025-05-18 11:00:48.883705", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 321, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 11:00:48.911597", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 322, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:00:48.947656", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "az", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 323, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:00:48.971025", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "mr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 324, "raw_pred": "G", "pred": "false", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 11:00:48.973819", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 325, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "true", "time": "2025-05-18 11:00:48.985543", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "nl", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 326, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:48.994676", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 327, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 11:00:48.995127", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 328, "raw_pred": "G", "pred": "false", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 11:00:49.018831", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 330, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:49.043070", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 329, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:49.048888", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "mr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 331, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:49.078862", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 332, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:49.114048", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 333, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:00:49.167328", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 334, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 11:00:49.167978", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 335, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:49.178541", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 338, "raw_pred": "D", "pred": "complicated/hard to categorise", "ground_truth": "false", "time": "2025-05-18 11:00:49.179007", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 337, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:49.183910", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 336, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "mostly false", "time": "2025-05-18 11:00:49.186799", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 339, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:49.205302", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 340, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 11:00:49.219721", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 341, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 11:00:49.251636", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 342, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:49.271868", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 343, "raw_pred": "G", "pred": "false", "ground_truth": "mostly true", "time": "2025-05-18 11:00:49.411547", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 344, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 11:00:49.465576", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 345, "raw_pred": "G", "pred": "false", "ground_truth": "true", "time": "2025-05-18 11:00:49.724762", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 346, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 11:00:49.746441", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 347, "raw_pred": "A", "pred": "true", "ground_truth": "false", "time": "2025-05-18 11:00:49.765773", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "az", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 348, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 11:00:49.776134", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "az", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 350, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:00:49.800611", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "nl", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 349, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:49.805683", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 352, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:49.813670", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 354, "raw_pred": "F", "pred": "mostly false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:00:49.816945", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 353, "raw_pred": "A", "pred": "true", "ground_truth": "false", "time": "2025-05-18 11:00:49.823541", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "az", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 351, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:49.826542", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "mr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 355, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:49.891900", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 356, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:49.914841", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 358, "raw_pred": "D", "pred": "complicated/hard to categorise", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:00:49.934926", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 357, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:49.935266", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "az", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 359, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 11:00:49.963578", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 360, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:50.012042", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 361, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:50.035958", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 364, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 11:00:50.067038", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 362, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 11:00:50.073009", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 363, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:50.079037", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 365, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:00:50.088159", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "pa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 366, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 11:00:50.114212", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 368, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:00:50.118446", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "az", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 367, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:00:50.120268", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "pa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 369, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:00:50.129382", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "gu", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 370, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 11:00:50.173276", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 371, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 11:00:50.191183", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "nl", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 372, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:50.240175", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "pa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 374, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 11:00:50.248153", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "nl", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 373, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:50.252180", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 375, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 11:00:50.253919", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "az", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 377, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:50.299093", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 376, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 11:00:50.304741", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 378, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:00:50.318677", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "gu", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 379, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 11:00:50.320104", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 380, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 11:00:50.337000", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 381, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "mostly false", "time": "2025-05-18 11:00:50.361290", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 382, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 11:00:50.401375", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 383, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:50.419720", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 384, "raw_pred": "G", "pred": "false", "ground_truth": "true", "time": "2025-05-18 11:00:50.438965", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 385, "raw_pred": "D", "pred": "complicated/hard to categorise", "ground_truth": "other", "time": "2025-05-18 11:00:50.443514", "score": 0, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 386, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:50.466294", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 387, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 11:00:50.467160", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 389, "raw_pred": "G", "pred": "false", "ground_truth": "true", "time": "2025-05-18 11:00:50.493604", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 390, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:50.511602", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "nl", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 388, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:50.511908", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 391, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:00:50.530546", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "si", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 392, "raw_pred": "G", "pred": "false", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 11:00:50.557175", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 393, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:00:50.586696", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 394, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 11:00:50.606562", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 395, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:50.624986", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 400, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:50.771519", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "nl", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 399, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:00:50.785967", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 402, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 11:00:50.812059", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 401, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:50.814337", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "az", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 398, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 11:00:50.815806", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 396, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:00:50.815450", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "az", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 404, "raw_pred": "A", "pred": "true", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:00:50.816129", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "az", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 397, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:00:50.816780", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 405, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 11:00:50.817357", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 403, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 11:00:50.822722", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 406, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:00:50.967733", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 407, "raw_pred": "F", "pred": "mostly false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:00:50.981359", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 408, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 11:00:51.313345", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 414, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 11:00:51.522036", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 413, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:51.531674", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "nl", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 410, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:00:51.542731", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 412, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:51.545141", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 418, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:51.555723", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "si", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 409, "raw_pred": "F", "pred": "mostly false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:00:51.559422", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 411, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:00:51.561927", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 417, "raw_pred": "G", "pred": "false", "ground_truth": "true", "time": "2025-05-18 11:00:51.562874", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 415, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:00:51.568634", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 416, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:00:51.570263", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "pa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 419, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 11:00:51.692951", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 420, "raw_pred": "G", "pred": "false", "ground_truth": "true", "time": "2025-05-18 11:00:51.753134", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 421, "raw_pred": "F", "pred": "mostly false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:00:52.005814", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 422, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:52.070714", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 423, "raw_pred": "A", "pred": "true", "ground_truth": "true", "time": "2025-05-18 11:00:52.229760", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 425, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 11:00:52.268546", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 426, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 11:00:52.277126", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 428, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:52.282420", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 424, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:52.283227", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 427, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:52.297032", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 431, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:00:52.309737", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "mr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 430, "raw_pred": "G", "pred": "false", "ground_truth": "other", "time": "2025-05-18 11:00:52.310536", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 429, "raw_pred": "F", "pred": "mostly false", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 11:00:52.311780", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 432, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 11:00:52.334241", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 433, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:52.429295", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "mr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 434, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 11:00:52.477966", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "mr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 435, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:52.576380", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 436, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 11:00:52.705102", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "nl", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 437, "raw_pred": "F", "pred": "mostly false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:00:52.748381", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 438, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:52.845618", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 440, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "mostly true", "time": "2025-05-18 11:00:52.935235", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 439, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:52.949960", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 442, "raw_pred": "D", "pred": "complicated/hard to categorise", "ground_truth": "true", "time": "2025-05-18 11:00:52.958853", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "az", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 441, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 11:00:52.968942", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 444, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:53.010563", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 443, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:00:53.021946", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 445, "raw_pred": "G", "pred": "false", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 11:00:53.037028", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 448, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:53.054573", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "si", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 446, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:53.054827", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "az", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 447, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 11:00:53.057087", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 449, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:53.104656", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 450, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 11:00:53.127151", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 451, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:00:53.151225", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "mr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 452, "raw_pred": "G", "pred": "false", "ground_truth": "true", "time": "2025-05-18 11:00:53.162622", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "az", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 453, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:00:53.173364", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "si", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 454, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:00:53.179290", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 455, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 11:00:53.194021", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 456, "raw_pred": "G", "pred": "false", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 11:00:53.234666", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 458, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:00:53.237276", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 457, "raw_pred": "A", "pred": "true", "ground_truth": "true", "time": "2025-05-18 11:00:53.246171", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 459, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:00:53.265072", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "mr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 460, "raw_pred": "G", "pred": "false", "ground_truth": "other", "time": "2025-05-18 11:00:53.295212", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 462, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:53.317040", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 461, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 11:00:53.327270", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 463, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:00:53.340032", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "pa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 464, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:53.340288", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 465, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 11:00:53.374379", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 467, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:00:53.407408", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "pa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 468, "raw_pred": "G", "pred": "false", "ground_truth": "other", "time": "2025-05-18 11:00:53.408251", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 466, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:53.414603", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 469, "raw_pred": "G", "pred": "false", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 11:00:53.428397", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 470, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 11:00:53.460274", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "nl", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 472, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 11:00:53.493677", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "gu", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 471, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:00:53.502096", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 473, "raw_pred": "A", "pred": "true", "ground_truth": "false", "time": "2025-05-18 11:00:53.503851", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 474, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:53.508670", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 475, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:53.544631", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 476, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 11:00:53.579584", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 477, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:53.582477", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 479, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:53.599538", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "nl", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 478, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 11:00:53.607276", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 480, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:53.616164", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "nl", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 481, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:53.666753", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 484, "raw_pred": "G", "pred": "false", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 11:00:53.675672", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 482, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 11:00:53.689807", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 483, "raw_pred": "G", "pred": "false", "ground_truth": "true", "time": "2025-05-18 11:00:53.691524", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 485, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:00:53.721863", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "pa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 486, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 11:00:53.749706", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 487, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:00:53.755648", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "pa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 488, "raw_pred": "F", "pred": "mostly false", "ground_truth": "true", "time": "2025-05-18 11:00:53.764812", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 490, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 11:00:53.775684", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 489, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 11:00:53.778914", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 3, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 11:08:26.406343", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 2, "raw_pred": "A", "pred": "true", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:08:26.413443", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "mr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 4, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:08:26.416710", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "gu", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 1, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:08:26.419429", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 0, "raw_pred": "G", "pred": "false", "ground_truth": "true", "time": "2025-05-18 11:08:26.433152", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 5, "raw_pred": "G", "pred": "false", "ground_truth": "mostly true", "time": "2025-05-18 11:08:26.655253", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 7, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:08:26.665095", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 6, "raw_pred": "G", "pred": "false", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 11:08:26.670727", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 9, "raw_pred": "G", "pred": "false", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 11:08:26.676666", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 8, "raw_pred": "F", "pred": "mostly false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:08:26.679185", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 10, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:08:26.872280", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "si", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 11, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 11:08:26.884681", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "nl", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 14, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:08:26.895502", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 12, "raw_pred": "D", "pred": "complicated/hard to categorise", "ground_truth": "mostly false", "time": "2025-05-18 11:08:26.904607", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "az", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 13, "raw_pred": "G", "pred": "false", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 11:08:26.911605", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 15, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:08:27.054704", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 16, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:08:27.055762", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 17, "raw_pred": "D", "pred": "complicated/hard to categorise", "ground_truth": "false", "time": "2025-05-18 11:08:27.087022", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 18, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:08:27.088052", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "mr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 19, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:08:27.103057", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "az", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 21, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:08:27.228010", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 20, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 11:08:27.246348", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 22, "raw_pred": "A", "pred": "true", "ground_truth": "false", "time": "2025-05-18 11:08:27.268324", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "az", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 24, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 11:08:27.276274", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 23, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:08:27.283363", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 25, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:08:27.405774", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "pa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 26, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 11:08:27.431178", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 27, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:08:27.431928", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 28, "raw_pred": "D", "pred": "complicated/hard to categorise", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:08:27.442339", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 29, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:08:27.459611", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 30, "raw_pred": "G", "pred": "false", "ground_truth": "true", "time": "2025-05-18 11:08:27.598154", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 32, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:08:27.603884", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 31, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:08:27.620680", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 34, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 11:08:27.625612", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 33, "raw_pred": "A", "pred": "true", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 11:08:27.629012", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 35, "raw_pred": "G", "pred": "false", "ground_truth": "mostly true", "time": "2025-05-18 11:08:27.767216", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 36, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:08:27.796923", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 37, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:08:27.806653", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 39, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "mostly false", "time": "2025-05-18 11:08:27.818404", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 38, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:08:27.825030", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 40, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 11:08:27.939723", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "nl", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 41, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:08:27.967168", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 43, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:08:27.986643", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 42, "raw_pred": "G", "pred": "false", "ground_truth": "mostly true", "time": "2025-05-18 11:08:27.989451", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 44, "raw_pred": "G", "pred": "false", "ground_truth": "true", "time": "2025-05-18 11:08:27.989966", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 45, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:08:28.102175", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 46, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 11:08:28.135949", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 48, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:08:28.171727", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 47, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:08:28.179940", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 49, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:08:28.186837", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 50, "raw_pred": "G", "pred": "false", "ground_truth": "true", "time": "2025-05-18 11:08:28.260279", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 51, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:08:28.296809", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "si", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 52, "raw_pred": "A", "pred": "true", "ground_truth": "false", "time": "2025-05-18 11:08:28.349007", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "az", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 53, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 11:08:28.361692", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 54, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:08:28.367104", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "az", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 55, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 11:08:28.423496", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 56, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 11:08:28.468309", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 58, "raw_pred": "A", "pred": "true", "ground_truth": "true", "time": "2025-05-18 11:08:28.522840", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 57, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:08:28.524436", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "si", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 59, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 11:08:28.543235", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 60, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 11:08:28.584490", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 61, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:08:28.638725", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 62, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 11:08:28.702804", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 63, "raw_pred": "G", "pred": "false", "ground_truth": "true", "time": "2025-05-18 11:08:28.712325", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 64, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:08:28.714630", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 65, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 11:08:28.756668", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 66, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:08:28.810791", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 67, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:08:28.877011", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "mr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 69, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 11:08:28.885364", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 68, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:08:28.909907", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "pa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 70, "raw_pred": "F", "pred": "mostly false", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 11:08:28.921150", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 71, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:08:28.984320", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 73, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:08:29.057119", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 72, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:08:29.060980", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 74, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:08:29.071323", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 75, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:08:29.088703", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "mr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 76, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:08:29.156346", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "si", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 77, "raw_pred": "G", "pred": "false", "ground_truth": "true", "time": "2025-05-18 11:08:29.232723", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 78, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:08:29.245188", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 79, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 11:08:29.248512", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 80, "raw_pred": "G", "pred": "false", "ground_truth": "true", "time": "2025-05-18 11:08:29.263473", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 81, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:08:29.327009", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 82, "raw_pred": "D", "pred": "complicated/hard to categorise", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 11:08:29.407692", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 85, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:08:29.426557", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 83, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:08:29.427227", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 84, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:08:29.431339", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 86, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:08:29.505451", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 87, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 11:08:29.570591", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 89, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 11:08:29.603099", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 88, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:08:29.605116", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 90, "raw_pred": "G", "pred": "false", "ground_truth": "true", "time": "2025-05-18 11:08:29.622452", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 91, "raw_pred": "G", "pred": "false", "ground_truth": "true", "time": "2025-05-18 11:08:29.661600", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 92, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:08:29.736474", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 93, "raw_pred": "G", "pred": "false", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 11:08:29.766803", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 95, "raw_pred": "G", "pred": "false", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 11:08:29.785619", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 94, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:08:29.790541", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 96, "raw_pred": "D", "pred": "complicated/hard to categorise", "ground_truth": "mostly false", "time": "2025-05-18 11:08:29.836798", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 97, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 11:08:29.909484", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 98, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 11:08:29.945843", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 101, "raw_pred": "G", "pred": "false", "ground_truth": "true", "time": "2025-05-18 11:08:30.024369", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 102, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:08:30.084551", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 100, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:08:30.117801", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 99, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:08:30.130072", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "nl", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 103, "raw_pred": "G", "pred": "false", "ground_truth": "true", "time": "2025-05-18 11:08:30.174903", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "az", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 104, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 11:08:30.215252", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "nl", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 105, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 11:08:30.270760", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 107, "raw_pred": "G", "pred": "false", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 11:08:30.398374", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 106, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:08:30.418913", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 108, "raw_pred": "F", "pred": "mostly false", "ground_truth": "true", "time": "2025-05-18 11:08:30.428382", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 109, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 11:08:30.441595", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 110, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:08:30.443408", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "si", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 111, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 11:08:30.597464", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "mr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 112, "raw_pred": "G", "pred": "false", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 11:08:30.624042", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 114, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:08:30.656707", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 113, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:08:30.663316", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 115, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 11:08:30.675137", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 116, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:08:30.765638", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 117, "raw_pred": "G", "pred": "false", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 11:08:30.803171", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 118, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:08:30.831391", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "gu", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 120, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 11:08:30.837454", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 119, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 11:08:30.840478", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 121, "raw_pred": "A", "pred": "true", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 11:08:30.940137", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 122, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 11:08:30.962399", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 125, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:08:31.006577", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 123, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:08:31.010922", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 124, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 11:08:31.014987", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 126, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:08:31.138557", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "si", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 127, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:08:31.149822", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 129, "raw_pred": "F", "pred": "mostly false", "ground_truth": "mostly true", "time": "2025-05-18 11:08:31.232469", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 128, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:08:31.235258", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 130, "raw_pred": "D", "pred": "complicated/hard to categorise", "ground_truth": "true", "time": "2025-05-18 11:08:31.252465", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 131, "raw_pred": "F", "pred": "mostly false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:08:31.322740", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "nl", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 132, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:08:31.343467", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "nl", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 134, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:08:31.433723", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 135, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:08:31.439540", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "pa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 133, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:08:31.449065", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 136, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 11:08:31.506549", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 137, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:08:31.543089", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "gu", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 140, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:08:31.660886", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 138, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:08:31.665360", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "pa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 139, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 11:08:31.670987", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 141, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 11:08:31.691440", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 142, "raw_pred": "D", "pred": "complicated/hard to categorise", "ground_truth": "mostly true", "time": "2025-05-18 11:08:31.720155", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 144, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:08:31.861371", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 143, "raw_pred": "A", "pred": "true", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 11:08:31.865356", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 146, "raw_pred": "G", "pred": "false", "ground_truth": "true", "time": "2025-05-18 11:08:31.873194", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 147, "raw_pred": "F", "pred": "mostly false", "ground_truth": "true", "time": "2025-05-18 11:08:31.882977", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 145, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:08:31.889777", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 148, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:08:32.093420", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 149, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 11:08:32.100540", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 151, "raw_pred": "G", "pred": "false", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 11:08:32.116573", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "nl", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 152, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:08:32.117442", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 150, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 11:08:32.132549", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 153, "raw_pred": "G", "pred": "false", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 11:08:32.294244", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 154, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:08:32.307546", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "pa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 155, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 11:08:32.328469", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 157, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:08:32.352314", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "pa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 156, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:08:32.360240", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 158, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 11:08:32.474722", "score": 0.75, "model": "command-r", "provider": "cohere", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 159, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:08:32.492843", "score": 0.25, "model": "command-r", "provider": "cohere", "language": "pa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 160, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:08:32.518692", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "sq", "prompt_type": "mcq"}
{"score": 0}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 161, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 11:08:32.554133", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 163, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:08:32.666361", "score": 1.0, "model": "command-r", "provider": "cohere", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 164, "raw_pred": "D", "pred": "complicated/hard to categorise", "ground_truth": "mostly false", "time": "2025-05-18 11:08:32.711790", "score": 0.5, "model": "command-r", "provider": "cohere", "language": "az", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 165, "raw_pred": "G", "pred": "false", "ground_truth": "true", "time": "2025-05-18 11:08:32.714130", "score": 0.0, "model": "command-r", "provider": "cohere", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 2, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:08:48.429179", "score": 0.25, "model": "gemini-2.0-flash", "provider": "gemini", "language": "mr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 1, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:08:48.430742", "score": 0.25, "model": "gemini-2.0-flash", "provider": "gemini", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 0, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "true", "time": "2025-05-18 11:08:48.458076", "score": 0.5, "model": "gemini-2.0-flash", "provider": "gemini", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 4, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:08:48.476038", "score": 0.25, "model": "gemini-2.0-flash", "provider": "gemini", "language": "gu", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 3, "raw_pred": "D", "pred": "complicated/hard to categorise", "ground_truth": "false", "time": "2025-05-18 11:08:48.508143", "score": 0.5, "model": "gemini-2.0-flash", "provider": "gemini", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 5, "raw_pred": "A", "pred": "true", "ground_truth": "mostly true", "time": "2025-05-18 11:08:48.873659", "score": 0.75, "model": "gemini-2.0-flash", "provider": "gemini", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 8, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:08:48.915331", "score": 0.25, "model": "gemini-2.0-flash", "provider": "gemini", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 6, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 11:08:48.923916", "score": 0.0, "model": "gemini-2.0-flash", "provider": "gemini", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 7, "raw_pred": "D", "pred": "complicated/hard to categorise", "ground_truth": "false", "time": "2025-05-18 11:08:48.934099", "score": 0.5, "model": "gemini-2.0-flash", "provider": "gemini", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 9, "raw_pred": "D", "pred": "complicated/hard to categorise", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 11:08:48.943863", "score": 1.0, "model": "gemini-2.0-flash", "provider": "gemini", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 13, "raw_pred": "D", "pred": "complicated/hard to categorise", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 11:08:49.313775", "score": 1.0, "model": "gemini-2.0-flash", "provider": "gemini", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 10, "raw_pred": "D", "pred": "complicated/hard to categorise", "ground_truth": "false", "time": "2025-05-18 11:08:49.314107", "score": 0.5, "model": "gemini-2.0-flash", "provider": "gemini", "language": "si", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 11, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 11:08:49.334738", "score": 0.5, "model": "gemini-2.0-flash", "provider": "gemini", "language": "nl", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 12, "raw_pred": "D", "pred": "complicated/hard to categorise", "ground_truth": "mostly false", "time": "2025-05-18 11:08:49.382176", "score": 0.5, "model": "gemini-2.0-flash", "provider": "gemini", "language": "az", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 14, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:08:49.404500", "score": 1.0, "model": "gemini-2.0-flash", "provider": "gemini", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 0, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "true", "time": "2025-05-18 11:09:51.567826", "score": 0.5, "model": "gemini-1.5-flash", "provider": "gemini", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 4, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:09:51.568090", "score": 0.25, "model": "gemini-1.5-flash", "provider": "gemini", "language": "gu", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 3, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 11:09:51.566794", "score": 0.5, "model": "gemini-1.5-flash", "provider": "gemini", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 1, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:09:51.568238", "score": 0.25, "model": "gemini-1.5-flash", "provider": "gemini", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 2, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:09:51.576731", "score": 1.0, "model": "gemini-1.5-flash", "provider": "gemini", "language": "mr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 5, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "mostly true", "time": "2025-05-18 11:09:52.077005", "score": 0.75, "model": "gemini-1.5-flash", "provider": "gemini", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 7, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 11:09:52.077173", "score": 0.5, "model": "gemini-1.5-flash", "provider": "gemini", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 6, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 11:09:52.076222", "score": 0.0, "model": "gemini-1.5-flash", "provider": "gemini", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 8, "raw_pred": "F", "pred": "mostly false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:09:52.077457", "score": 0.5, "model": "gemini-1.5-flash", "provider": "gemini", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 9, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 11:09:52.150643", "score": 0.0, "model": "gemini-1.5-flash", "provider": "gemini", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 11, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 11:09:52.484114", "score": 0.5, "model": "gemini-1.5-flash", "provider": "gemini", "language": "nl", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 12, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "mostly false", "time": "2025-05-18 11:09:52.484912", "score": 0.5, "model": "gemini-1.5-flash", "provider": "gemini", "language": "az", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 10, "raw_pred": "D", "pred": "complicated/hard to categorise", "ground_truth": "false", "time": "2025-05-18 11:09:52.485236", "score": 0.5, "model": "gemini-1.5-flash", "provider": "gemini", "language": "si", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 13, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 11:09:52.485075", "score": 0.0, "model": "gemini-1.5-flash", "provider": "gemini", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 14, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 11:09:52.502164", "score": 0.5, "model": "gemini-1.5-flash", "provider": "gemini", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 0, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "true", "time": "2025-05-18 11:13:26.717979", "score": 0.5, "model": "gemini-1.5-flash", "provider": "gemini", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 3, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 11:13:26.719794", "score": 0.5, "model": "gemini-1.5-flash", "provider": "gemini", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 4, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:13:26.719559", "score": 1.0, "model": "gemini-1.5-flash", "provider": "gemini", "language": "gu", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 1, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:13:26.720627", "score": 0.25, "model": "gemini-1.5-flash", "provider": "gemini", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 2, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:13:26.721404", "score": 1.0, "model": "gemini-1.5-flash", "provider": "gemini", "language": "mr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 8, "raw_pred": "F", "pred": "mostly false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:13:27.226410", "score": 0.5, "model": "gemini-1.5-flash", "provider": "gemini", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 7, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 11:13:27.227400", "score": 0.5, "model": "gemini-1.5-flash", "provider": "gemini", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 5, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "mostly true", "time": "2025-05-18 11:13:27.225301", "score": 0.75, "model": "gemini-1.5-flash", "provider": "gemini", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 6, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 11:13:27.227257", "score": 0.0, "model": "gemini-1.5-flash", "provider": "gemini", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 9, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 11:13:27.229646", "score": 0.0, "model": "gemini-1.5-flash", "provider": "gemini", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 14, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 11:13:27.657473", "score": 0.5, "model": "gemini-1.5-flash", "provider": "gemini", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 13, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 11:13:27.666577", "score": 0.0, "model": "gemini-1.5-flash", "provider": "gemini", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 10, "raw_pred": "D", "pred": "complicated/hard to categorise", "ground_truth": "false", "time": "2025-05-18 11:13:27.684125", "score": 0.5, "model": "gemini-1.5-flash", "provider": "gemini", "language": "si", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 11, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 11:13:27.700364", "score": 0.5, "model": "gemini-1.5-flash", "provider": "gemini", "language": "nl", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 12, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "mostly false", "time": "2025-05-18 11:13:27.715915", "score": 0.5, "model": "gemini-1.5-flash", "provider": "gemini", "language": "az", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 3, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 11:15:29.345728", "score": 0.5, "model": "gemini-1.5-flash", "provider": "gemini", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 1, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:15:29.345175", "score": 0.25, "model": "gemini-1.5-flash", "provider": "gemini", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 0, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "true", "time": "2025-05-18 11:15:29.372620", "score": 0.5, "model": "gemini-1.5-flash", "provider": "gemini", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 4, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:15:29.395634", "score": 0.25, "model": "gemini-1.5-flash", "provider": "gemini", "language": "gu", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 2, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:15:29.539045", "score": 1.0, "model": "gemini-1.5-flash", "provider": "gemini", "language": "mr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 6, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 11:15:29.717007", "score": 0.0, "model": "gemini-1.5-flash", "provider": "gemini", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 8, "raw_pred": "F", "pred": "mostly false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:15:29.720056", "score": 0.5, "model": "gemini-1.5-flash", "provider": "gemini", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 5, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "mostly true", "time": "2025-05-18 11:15:29.723411", "score": 0.75, "model": "gemini-1.5-flash", "provider": "gemini", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 7, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 11:15:29.731466", "score": 0.5, "model": "gemini-1.5-flash", "provider": "gemini", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 9, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 11:15:29.871067", "score": 0.0, "model": "gemini-1.5-flash", "provider": "gemini", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 12, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "mostly false", "time": "2025-05-18 11:15:30.118153", "score": 0.5, "model": "gemini-1.5-flash", "provider": "gemini", "language": "az", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 11, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 11:15:30.124938", "score": 0.5, "model": "gemini-1.5-flash", "provider": "gemini", "language": "nl", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 10, "raw_pred": "D", "pred": "complicated/hard to categorise", "ground_truth": "false", "time": "2025-05-18 11:15:30.126850", "score": 0.5, "model": "gemini-1.5-flash", "provider": "gemini", "language": "si", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 13, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 11:15:30.147886", "score": 0.0, "model": "gemini-1.5-flash", "provider": "gemini", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 14, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 11:15:30.294212", "score": 0.5, "model": "gemini-1.5-flash", "provider": "gemini", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 17, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 11:15:30.478779", "score": 0.5, "model": "gemini-1.5-flash", "provider": "gemini", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 18, "raw_pred": "F", "pred": "mostly false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:15:30.509213", "score": 0.5, "model": "gemini-1.5-flash", "provider": "gemini", "language": "mr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 16, "raw_pred": "F", "pred": "mostly false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:15:30.519993", "score": 0.5, "model": "gemini-1.5-flash", "provider": "gemini", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 15, "raw_pred": "F", "pred": "mostly false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:15:30.560335", "score": 0.5, "model": "gemini-1.5-flash", "provider": "gemini", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 19, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 11:15:30.656124", "score": 0.5, "model": "gemini-1.5-flash", "provider": "gemini", "language": "az", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 22, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 11:15:30.791801", "score": 0.5, "model": "gemini-1.5-flash", "provider": "gemini", "language": "az", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 20, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "mostly false", "time": "2025-05-18 11:15:30.811931", "score": 0.5, "model": "gemini-1.5-flash", "provider": "gemini", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 21, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:15:30.814465", "score": 1.0, "model": "gemini-1.5-flash", "provider": "gemini", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 23, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 11:15:30.892533", "score": 0.75, "model": "gemini-1.5-flash", "provider": "gemini", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 24, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "mostly false", "time": "2025-05-18 11:15:30.980576", "score": 0.5, "model": "gemini-1.5-flash", "provider": "gemini", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 25, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:15:31.120133", "score": 0.25, "model": "gemini-1.5-flash", "provider": "gemini", "language": "pa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 26, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:15:31.133966", "score": 1.0, "model": "gemini-1.5-flash", "provider": "gemini", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 27, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 11:15:31.149440", "score": 0.75, "model": "gemini-1.5-flash", "provider": "gemini", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 28, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:15:31.198025", "score": 1.0, "model": "gemini-1.5-flash", "provider": "gemini", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 29, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:15:31.294982", "score": 1.0, "model": "gemini-1.5-flash", "provider": "gemini", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 31, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:15:31.445813", "score": 1.0, "model": "gemini-1.5-flash", "provider": "gemini", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 30, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "true", "time": "2025-05-18 11:15:31.453300", "score": 0.5, "model": "gemini-1.5-flash", "provider": "gemini", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 32, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 11:15:31.461983", "score": 0.5, "model": "gemini-1.5-flash", "provider": "gemini", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 33, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 11:15:31.492856", "score": 0.0, "model": "gemini-1.5-flash", "provider": "gemini", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 34, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "mostly false", "time": "2025-05-18 11:15:31.626483", "score": 0.5, "model": "gemini-1.5-flash", "provider": "gemini", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 35, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "mostly true", "time": "2025-05-18 11:15:31.783626", "score": 0.75, "model": "gemini-1.5-flash", "provider": "gemini", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 37, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 11:15:31.795104", "score": 0.75, "model": "gemini-1.5-flash", "provider": "gemini", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 38, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:15:31.814659", "score": 1.0, "model": "gemini-1.5-flash", "provider": "gemini", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 36, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 11:15:31.818448", "score": 0.5, "model": "gemini-1.5-flash", "provider": "gemini", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 39, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "mostly false", "time": "2025-05-18 11:15:31.954171", "score": 0.5, "model": "gemini-1.5-flash", "provider": "gemini", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 40, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 11:15:32.105740", "score": 0.5, "model": "gemini-1.5-flash", "provider": "gemini", "language": "nl", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 42, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "mostly true", "time": "2025-05-18 11:15:32.130158", "score": 0.75, "model": "gemini-1.5-flash", "provider": "gemini", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 43, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 11:15:32.153937", "score": 0.5, "model": "gemini-1.5-flash", "provider": "gemini", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 41, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 11:15:32.158337", "score": 0.5, "model": "gemini-1.5-flash", "provider": "gemini", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 44, "raw_pred": "D", "pred": "complicated/hard to categorise", "ground_truth": "true", "time": "2025-05-18 11:15:32.249695", "score": 0.0, "model": "gemini-1.5-flash", "provider": "gemini", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 47, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:15:32.428969", "score": 1.0, "model": "gemini-1.5-flash", "provider": "gemini", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 45, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 11:15:32.450202", "score": 0.5, "model": "gemini-1.5-flash", "provider": "gemini", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 48, "raw_pred": "D", "pred": "complicated/hard to categorise", "ground_truth": "false", "time": "2025-05-18 11:15:32.462077", "score": 0.5, "model": "gemini-1.5-flash", "provider": "gemini", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 46, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 11:15:32.475931", "score": 0.5, "model": "gemini-1.5-flash", "provider": "gemini", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 49, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 11:15:32.553000", "score": 0.5, "model": "gemini-1.5-flash", "provider": "gemini", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 50, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "true", "time": "2025-05-18 11:15:32.740392", "score": 0.5, "model": "gemini-1.5-flash", "provider": "gemini", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 52, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 11:15:32.765109", "score": 0.5, "model": "gemini-1.5-flash", "provider": "gemini", "language": "az", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 51, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 11:15:32.773445", "score": 0.5, "model": "gemini-1.5-flash", "provider": "gemini", "language": "si", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 53, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 11:15:32.804507", "score": 0.75, "model": "gemini-1.5-flash", "provider": "gemini", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 54, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 11:15:32.864182", "score": 0.75, "model": "gemini-1.5-flash", "provider": "gemini", "language": "az", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 55, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 11:15:33.048804", "score": 0.5, "model": "gemini-1.5-flash", "provider": "gemini", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 57, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:15:33.086272", "score": 0.25, "model": "gemini-1.5-flash", "provider": "gemini", "language": "si", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 58, "raw_pred": "A", "pred": "true", "ground_truth": "true", "time": "2025-05-18 11:15:33.101191", "score": 1.0, "model": "gemini-1.5-flash", "provider": "gemini", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 59, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "mostly false", "time": "2025-05-18 11:15:33.149991", "score": 0.5, "model": "gemini-1.5-flash", "provider": "gemini", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 56, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "mostly false", "time": "2025-05-18 11:15:33.196026", "score": 0.5, "model": "gemini-1.5-flash", "provider": "gemini", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 60, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 11:15:33.351433", "score": 0.5, "model": "gemini-1.5-flash", "provider": "gemini", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 62, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 11:15:33.398147", "score": 0.75, "model": "gemini-1.5-flash", "provider": "gemini", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 61, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 11:15:33.428585", "score": 0.5, "model": "gemini-1.5-flash", "provider": "gemini", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 64, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 11:15:33.476742", "score": 0.75, "model": "gemini-1.5-flash", "provider": "gemini", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 63, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "true", "time": "2025-05-18 11:15:33.560597", "score": 0.5, "model": "gemini-1.5-flash", "provider": "gemini", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 65, "raw_pred": "F", "pred": "mostly false", "ground_truth": "mostly false", "time": "2025-05-18 11:15:33.662373", "score": 1.0, "model": "gemini-1.5-flash", "provider": "gemini", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 67, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:15:33.710608", "score": 1.0, "model": "gemini-1.5-flash", "provider": "gemini", "language": "mr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 66, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:15:33.726750", "score": 1.0, "model": "gemini-1.5-flash", "provider": "gemini", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 68, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:15:33.770766", "score": 1.0, "model": "gemini-1.5-flash", "provider": "gemini", "language": "pa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 69, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 11:15:33.873141", "score": 0.75, "model": "gemini-1.5-flash", "provider": "gemini", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 71, "raw_pred": "D", "pred": "complicated/hard to categorise", "ground_truth": "false", "time": "2025-05-18 11:15:33.975196", "score": 0.5, "model": "gemini-1.5-flash", "provider": "gemini", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 70, "raw_pred": "G", "pred": "false", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 11:15:34.001136", "score": 0.0, "model": "gemini-1.5-flash", "provider": "gemini", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 72, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 11:15:34.026997", "score": 0.5, "model": "gemini-1.5-flash", "provider": "gemini", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 73, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:15:34.096251", "score": 0.25, "model": "gemini-1.5-flash", "provider": "gemini", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 74, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 11:15:34.166008", "score": 0.5, "model": "gemini-1.5-flash", "provider": "gemini", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 75, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:15:34.294416", "score": 1.0, "model": "gemini-1.5-flash", "provider": "gemini", "language": "mr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 76, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 11:15:34.300686", "score": 0.5, "model": "gemini-1.5-flash", "provider": "gemini", "language": "si", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 77, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "true", "time": "2025-05-18 11:15:34.322021", "score": 0.5, "model": "gemini-1.5-flash", "provider": "gemini", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 78, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:15:34.389280", "score": 1.0, "model": "gemini-1.5-flash", "provider": "gemini", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 79, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 11:15:34.561070", "score": 0.5, "model": "gemini-1.5-flash", "provider": "gemini", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 81, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 11:15:34.618452", "score": 0.5, "model": "gemini-1.5-flash", "provider": "gemini", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 80, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "true", "time": "2025-05-18 11:15:34.625398", "score": 0.5, "model": "gemini-1.5-flash", "provider": "gemini", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 82, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 11:15:34.642780", "score": 0.0, "model": "gemini-1.5-flash", "provider": "gemini", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 83, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 11:15:34.677749", "score": 0.5, "model": "gemini-1.5-flash", "provider": "gemini", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 84, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:15:34.865293", "score": 1.0, "model": "gemini-1.5-flash", "provider": "gemini", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 85, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:15:34.928173", "score": 0.25, "model": "gemini-1.5-flash", "provider": "gemini", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 87, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "mostly false", "time": "2025-05-18 11:15:34.928311", "score": 0.5, "model": "gemini-1.5-flash", "provider": "gemini", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 86, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:15:34.931464", "score": 1.0, "model": "gemini-1.5-flash", "provider": "gemini", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 88, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 11:15:34.980347", "score": 0.5, "model": "gemini-1.5-flash", "provider": "gemini", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 89, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 11:15:35.193886", "score": 0.5, "model": "gemini-1.5-flash", "provider": "gemini", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 90, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "true", "time": "2025-05-18 11:15:35.257976", "score": 0.5, "model": "gemini-1.5-flash", "provider": "gemini", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 92, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:15:35.258103", "score": 1.0, "model": "gemini-1.5-flash", "provider": "gemini", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 93, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 11:15:35.283572", "score": 0.0, "model": "gemini-1.5-flash", "provider": "gemini", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 91, "raw_pred": "G", "pred": "false", "ground_truth": "true", "time": "2025-05-18 11:15:35.286973", "score": 0.0, "model": "gemini-1.5-flash", "provider": "gemini", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 94, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:15:35.491251", "score": 1.0, "model": "gemini-1.5-flash", "provider": "gemini", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 98, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:15:35.585822", "score": 1.0, "model": "gemini-1.5-flash", "provider": "gemini", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 96, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "mostly false", "time": "2025-05-18 11:15:35.585974", "score": 0.5, "model": "gemini-1.5-flash", "provider": "gemini", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 97, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "mostly false", "time": "2025-05-18 11:15:35.586435", "score": 0.5, "model": "gemini-1.5-flash", "provider": "gemini", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 95, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 11:15:35.589974", "score": 0.0, "model": "gemini-1.5-flash", "provider": "gemini", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 99, "raw_pred": "F", "pred": "mostly false", "ground_truth": "false", "time": "2025-05-18 11:15:35.833921", "score": 0.75, "model": "gemini-1.5-flash", "provider": "gemini", "language": "nl", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 102, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 11:15:35.940966", "score": 0.5, "model": "gemini-1.5-flash", "provider": "gemini", "language": "fr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 101, "raw_pred": "F", "pred": "mostly false", "ground_truth": "true", "time": "2025-05-18 11:15:35.951577", "score": 0.0, "model": "gemini-1.5-flash", "provider": "gemini", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 103, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "true", "time": "2025-05-18 11:15:35.956555", "score": 0.5, "model": "gemini-1.5-flash", "provider": "gemini", "language": "az", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 100, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 11:15:35.966236", "score": 0.5, "model": "gemini-1.5-flash", "provider": "gemini", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 104, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 11:15:36.135051", "score": 0.5, "model": "gemini-1.5-flash", "provider": "gemini", "language": "nl", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 105, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 11:15:36.260929", "score": 0.5, "model": "gemini-1.5-flash", "provider": "gemini", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 106, "raw_pred": "G", "pred": "false", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:15:36.297087", "score": 0.25, "model": "gemini-1.5-flash", "provider": "gemini", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 108, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "true", "time": "2025-05-18 11:15:36.297214", "score": 0.5, "model": "gemini-1.5-flash", "provider": "gemini", "language": "no", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 107, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 11:15:36.356747", "score": 0.0, "model": "gemini-1.5-flash", "provider": "gemini", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 109, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:15:36.435939", "score": 1.0, "model": "gemini-1.5-flash", "provider": "gemini", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 110, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 11:15:36.585919", "score": 0.5, "model": "gemini-1.5-flash", "provider": "gemini", "language": "si", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 111, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:15:36.596338", "score": 1.0, "model": "gemini-1.5-flash", "provider": "gemini", "language": "mr", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 112, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 11:15:36.635613", "score": 0.0, "model": "gemini-1.5-flash", "provider": "gemini", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 113, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 11:15:36.673749", "score": 0.5, "model": "gemini-1.5-flash", "provider": "gemini", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 114, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:15:36.717273", "score": 1.0, "model": "gemini-1.5-flash", "provider": "gemini", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 117, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 11:15:36.967248", "score": 0.0, "model": "gemini-1.5-flash", "provider": "gemini", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 115, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "mostly false", "time": "2025-05-18 11:15:36.968680", "score": 0.5, "model": "gemini-1.5-flash", "provider": "gemini", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 116, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:15:36.968908", "score": 1.0, "model": "gemini-1.5-flash", "provider": "gemini", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 118, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 11:15:36.986655", "score": 0.5, "model": "gemini-1.5-flash", "provider": "gemini", "language": "gu", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 119, "raw_pred": "F", "pred": "mostly false", "ground_truth": "mostly false", "time": "2025-05-18 11:15:36.997251", "score": 1.0, "model": "gemini-1.5-flash", "provider": "gemini", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 124, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "mostly false", "time": "2025-05-18 11:15:37.371457", "score": 0.5, "model": "gemini-1.5-flash", "provider": "gemini", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 123, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "partly true/misleading", "time": "2025-05-18 11:15:37.371849", "score": 1.0, "model": "gemini-1.5-flash", "provider": "gemini", "language": "ru", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 121, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "complicated/hard to categorise", "time": "2025-05-18 11:15:37.379642", "score": 0.0, "model": "gemini-1.5-flash", "provider": "gemini", "language": "fa", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 122, "raw_pred": "C", "pred": "partly true/misleading", "ground_truth": "false", "time": "2025-05-18 11:15:37.386982", "score": 0.5, "model": "gemini-1.5-flash", "provider": "gemini", "language": "sq", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 120, "raw_pred": "G", "pred": "false", "ground_truth": "mostly false", "time": "2025-05-18 11:15:37.387161", "score": 0.75, "model": "gemini-1.5-flash", "provider": "gemini", "language": "bn", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 126, "raw_pred": "A", "pred": "true", "ground_truth": "false", "time": "2025-05-18 11:15:37.765882", "score": 0.0, "model": "gemini-1.5-flash", "provider": "gemini", "language": "si", "prompt_type": "mcq"}
{"dataset": "x-fact-zero-shot", "idx_after_dropna": 125, "raw_pred": "G", "pred": "false", "ground_truth": "false", "time": "2025-05-18 11:15:37.787098", "score": 1.0, "model": "gemini-1.5-flash", "provider": "gemini", "language": "ru", "prompt_type": "mcq"}
